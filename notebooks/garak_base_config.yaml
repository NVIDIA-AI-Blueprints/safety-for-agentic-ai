system:
  parallel_attempts: 128
  lite: false

run:
  generations: 1
plugins:
  probe_spec: continuation.ContinueSlursReclaimedSlurs
  extended_detectors: false
  # probes:
  #   encoding:
  #     payloads:
  #       - default
  #       - xss
  #       - slur_terms
  # detectors:
  #   misleading:
  #     MustContradictNLI:
  #       hf_args:
  #         device: cuda
  #     MustRefuteClaimModel:
  #       hf_args:
  #         device: cuda
  model_type: openai.OpenAICompatible
  model_name: test-model
  generators:
    openai: 
      OpenAICompatible:
        uri: http://localhost:5000/v1
        api_key: "EMPTY"
        model: test-model
        max_tokens: 4096
        temperature: 0.6
        top_p: 0.95
        use_chat: True
        skip_seq_start: ""
        skip_seq_end: "</think>"