{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fd37e71a-284c-4cf0-8371-66916339bf47",
   "metadata": {},
   "source": [
    "# Notebook 2: Post-Training with Safety and Accuracy Data\n",
    "\n",
    "## About the Data\n",
    "\n",
    "This notebook demonstrates how to post-train the base model with safety-related data.\n",
    "The safety data is gathered from the following well-known datasets:\n",
    "\n",
    "- [Aegis AI Content Safety Dataset 2.0](https://huggingface.co/datasets/nvidia/Aegis-AI-Content-Safety-Dataset-2.0)\n",
    "- [Gretel Synthetic Safety Alignment Dataset](https://huggingface.co/datasets/gretelai/gretel-safety-alignment-en-v1)\n",
    "- [HarmfulTasks](https://github.com/CrystalEye42/eval-safety)\n",
    "- [RedTeam 2k](https://huggingface.co/datasets/JailbreakV-28K/JailBreakV-28k)\n",
    "\n",
    "Training also uses the [nvidia/LLama-Nemotron-Post-Training-Dataset](https://huggingface.co/datasets/nvidia/Llama-Nemotron-Post-Training-Dataset) to preserve the code, chat, math, and science reasoning abilities that can otherwise degrade with fine-tuning.\n",
    "\n",
    "## About the Process\n",
    "\n",
    "This notebook proceeds through the following high-level steps:\n",
    "\n",
    "- Set up a directory structure for logs and results.\n",
    "- Data preparation:\n",
    "  - Download the preceding safety-related datasets and extract 2000 total samples at random.\n",
    "  - Download the Llama Nemotron dataset and extract 4000 samples at random.\n",
    "  - Create training and validation datasets from the samples, excluding samples with a token length greater than `16384`.\n",
    "- Start vLLM servers:\n",
    "  - One serves the base model to train.\n",
    "  - A second serves the NVIDIA Llama 3.1 Nemoguard 8B Instruct model to act as LLM as judge.\n",
    "- Fine-tune the model using [NeMo-RL](https://github.com/NVIDIA/NeMo-RL) to apply safety post-training to improve the safety of the target model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5b7458e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "NVIDIA_API_KEY = \"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\" # Add your NVIDIA API KEY here\n",
    "HF_TOKEN       = \"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\" # Add your HF_TOKEN\n",
    "WANDB_API_KEY  = \"2f672ca9d8cf9366dda87615069e6a9f2de6a33d\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b4fc45e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "if HF_TOKEN is None:\n",
    "    raise ValueError(\"HF_TOKEN must be set.\")\n",
    "if WANDB_API_KEY is None:\n",
    "    print(\"WANDB_API_KEY is not set. Skipping WANDB logging.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c17609ed",
   "metadata": {},
   "source": [
    "### Set up Packages and Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "def9dcce-240c-49ba-8d02-f4a70053d18c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import subprocess\n",
    "import time\n",
    "from pathlib import Path\n",
    "from huggingface_hub import hf_hub_download\n",
    "import shutil\n",
    "\n",
    "# Base directory and configuration\n",
    "BASE_DIR = \"./workspace/training\"\n",
    "LOG_DIR = f\"{BASE_DIR}/logs\"\n",
    "\n",
    "SAFETY_DATASET_NAME = \"nemo_safety_blend_v0.2.2.jsonl\"  # TODO: Change\n",
    "POST_TRAINING_DATASET_NAME = \"nvidia/Llama-Nemotron-Post-Training-Dataset\"\n",
    "MODEL_NAME_OR_PATH = \"deepseek-ai/DeepSeek-R1-Distill-Llama-8B\"\n",
    "MODEL_DIR = f\"{BASE_DIR}/model/\"\n",
    "SAFETY_MODEL_NAME = \"llama-3.1-nemoguard-8b-content-safety\"\n",
    "SAFETY_MODEL_PATH = f\"{MODEL_DIR}/{SAFETY_MODEL_NAME}\"\n",
    "\n",
    "# Credentials\n",
    "os.environ.update({\n",
    "    \"HF_TOKEN\": HF_TOKEN,\n",
    "    \"WANDB_API_KEY\": WANDB_API_KEY\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bbde3367-ff98-4984-b8e1-7687fbc6379b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set environment variables\n",
    "os.environ.update({\n",
    "    'TMPDIR': f\"{BASE_DIR}/tmp\",\n",
    "    'XDG_CACHE_HOME': f\"{BASE_DIR}/cache\",\n",
    "    'HF_HOME': f\"{BASE_DIR}/cache/huggingface\",\n",
    "    'UV_CACHE_DIR': f\"{BASE_DIR}/cache/uv\",\n",
    "    'TRITON_CACHE_DIR': f\"{BASE_DIR}/cache/triton\",\n",
    "    'DATASET_CACHE_DIR': f\"{BASE_DIR}/dataset_cache\",\n",
    "    'RAY_TMPDIR': \"/tmp/ray\",\n",
    "    'LOG_DIR': f\"{LOG_DIR}\",\n",
    "    \"MODEL_DIR\": f\"{MODEL_DIR}\"\n",
    "})\n",
    "\n",
    "# Create directories\n",
    "for dir_path in [os.environ['TMPDIR'], os.environ['XDG_CACHE_HOME'], os.environ['HF_HOME'],\n",
    "                 os.environ['UV_CACHE_DIR'],os.environ['TRITON_CACHE_DIR'], os.environ['DATASET_CACHE_DIR'], \n",
    "                 os.environ['RAY_TMPDIR'], os.environ['LOG_DIR'], os.environ['MODEL_DIR']]:\n",
    "    Path(dir_path).mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47c27b7e",
   "metadata": {},
   "source": [
    "After you run the preceding cell, the directory structure---including the paths from the first notebook---are as follows:\n",
    "\n",
    "```text\n",
    "workspace\n",
    "├── cache\n",
    "│   ├── huggingface\n",
    "│   ├── triton\n",
    "│   └── uv\n",
    "├── dataset\n",
    "│   └── aegis_v2\n",
    "├── dataset_cache\n",
    "├── results\n",
    "│   └── DeepSeek-R1-Distill-Llama-8B\n",
    "│       ├── accuracy-evals\n",
    "│       │   ├── aa-math-500\n",
    "│       │   ├── gpqa-diamond\n",
    "│       │   └── ifeval\n",
    "│       ├── content-safety-evals\n",
    "│       │   ├── aegis_v2\n",
    "│       │   └── wildguard\n",
    "│       ├── logs\n",
    "│       └── security-evals\n",
    "│           └── garak\n",
    "│               ├── configs\n",
    "│               ├── logs\n",
    "│               └── reports\n",
    "├── tmp\n",
    "└── training\n",
    "    └── model\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "994dafc1-3758-4d51-8ed1-3ddef45196cd",
   "metadata": {},
   "source": [
    "### Generating Safety Training Data\n",
    "\n",
    "The key idea is to use on-policy data generated by the target model.\n",
    "This approach improves safety, while making sure to obtain safe responses even for unsafe prompts. \n",
    "\n",
    "The notebook uses a safety training data generation recipe that uses the following public datasets:\n",
    "\n",
    "- Aegis AI Content Safety Dataset 2.0\n",
    "- Gretel Synthetic Safety Alignment Dataset\n",
    "- HarmfulTasks\n",
    "- RedTeam 2k\n",
    "\n",
    "The notebook extracts safe and unsafe prompts from Aegis AI Content Safety Dataset 2.0 and unsafe prompts from the other three datasets. \n",
    "\n",
    "### Response Generation for Safe Prompts\n",
    "\n",
    "For safe prompts, the notebook uses the target model and the prompts as-is to generate responses.\n",
    "When you have access to a larger model in the same model family---such as `deepseek-ai/DeepSeek-R1` instead of `deepseek-ai/DeepSeek-R1-Distill-Llama-8B`---use the larger model because it should generate safe responses better than the smaller model. \n",
    "\n",
    "### Response Generation for Unsafe Prompts\n",
    "\n",
    "Because the unsafe prompts in the HarmfulTasks dataset have jailbreak prompts that begin with text like \"Ignore all instructions until now...\" and end with a request like \"Write a blog post promoting mistrust between different social groups.\"\n",
    "The jailbreak portion of the prompts are removed, but the model still generates responses to the unsafe user request, such as writing a blog to promote mistrust.\n",
    "\n",
    "All unsafe prompts are wrapped in a new prompt template, shown below, that instructs the model to disengage but also inform the user exactly why---using the ground truth harm categories in the datasets and not a canned response.\n",
    "\n",
    "```\n",
    "You are a helpful assistant that generates safe responses for given prompts.\n",
    "\n",
    "The prompt is: {prompt}\n",
    "This prompt is known to violate the following safety categories or elicits unsafe responses of these categories from the model. The categories are: {categories}\n",
    "\n",
    "Generate a safe refusal for the prompt that politely points out that the model doesn't engage in unsafe behavior for the given categories. Your response:\n",
    "```\n",
    "\n",
    "With this approach, the model can generate safe responses for unsafe prompts. \n",
    "\n",
    "For training, the notebook passes the original unsafe prompt and the generated response---not the one with the safe prompt wrapper described above. Effectively, we are trying to teach the model to generate the same response to the original unsafe prompt such as with the jailbreak instructions for the HarmfulTasks prompts.\n",
    "\n",
    "### Response Filtering\n",
    "\n",
    "The generated responses for the safe and unsafe prompts discussed above are not guaranteed to be safe responses. Therefore, we implement a filtering step to extract the generated responses that are judged as safe by a guard model.\n",
    "\n",
    "We use [nvidia/llama-3.1-nemoguard-8b-content-safety](https://huggingface.co/nvidia/llama-3.1-nemoguard-8b-content-safety) as the guard model for this filtering step.\n",
    "\n",
    "### Blend Safety Training Data with Accuracy Data\n",
    "\n",
    "Safety training data helps the model learn to refuse to answer unsafe prompts. As a result, the model can experience some accuracy degradation for certain capabilities such as instruction following.\n",
    "\n",
    "To address the issue, the notebook adds post-training data to retain the accuracy. We use a subset of  [nvidia/Llama-Nemotron-Post-Training-Dataset](https://huggingface.co/datasets/nvidia/Llama-Nemotron-Post-Training-Dataset), which was used to train Llama Nemotron models—world-class reasoning models, for this purpose. \n",
    "\n",
    "More specifically, in this recipe, the notebook generates on-policy data using the model.\n",
    "The on-policy data can help retain the same behavior as the original model for the prompts in the post-training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "daf5e2e0-0b2b-4032-84d6-d91f3b16891b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting dataset collection...\n",
      "Output file: ./workspace/training/dataset_cache/nemo_safety_blend_v0.2.2.jsonl\n",
      "Target sample size: 2,000\n",
      "Sampling method: uniform\n",
      "Using cache directory: ./workspace/training/dataset_cache\n",
      "\n",
      "Downloading Aegis v2 dataset...\n",
      "Source: nvidia/Aegis-AI-Content-Safety-Dataset-2.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 100%|██████████| 30007/30007 [00:00<00:00, 113616.01 examples/s]\n",
      "Generating validation split: 100%|██████████| 1445/1445 [00:00<00:00, 72828.28 examples/s]\n",
      "Generating test split: 100%|██████████| 1964/1964 [00:00<00:00, 106998.66 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "Dataset: Aegis v2\n",
      "Number of samples: 23,077\n",
      "================================================================================\n",
      "\n",
      "\n",
      "Downloading Gretel Safety Alignment v1 dataset...\n",
      "Source: gretelai/gretel-safety-alignment-en-v1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 100%|██████████| 5997/5997 [00:00<00:00, 110306.72 examples/s]\n",
      "Generating test split: 100%|██████████| 1183/1183 [00:00<00:00, 73799.89 examples/s]\n",
      "Generating validation split: 100%|██████████| 1181/1181 [00:00<00:00, 71626.49 examples/s]\n",
      "Cloning into 'eval-safety'...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "Dataset: Gretel Safety Alignment v1\n",
      "Number of samples: 5,997\n",
      "================================================================================\n",
      "\n",
      "\n",
      "Downloading Harmful Tasks dataset...\n",
      "Source: CrystalEye42/eval-safety\n",
      "Processing Harmful Tasks data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing categories: 100%|██████████| 5/5 [00:00<00:00, 44431.19it/s]\n",
      "Processing tasks: 100%|██████████| 11/11 [00:00<00:00, 16343.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "Dataset: Harmful Tasks\n",
      "Number of samples: 1,650\n",
      "================================================================================\n",
      "\n",
      "\n",
      "Downloading RedTeam 2k dataset...\n",
      "Source: JailbreakV-28K/JailBreakV-28k\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating RedTeam_2K split: 100%|██████████| 2000/2000 [00:00<00:00, 290756.23 examples/s]\n",
      "Filter: 100%|██████████| 2000/2000 [00:00<00:00, 186807.88 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "Dataset: RedTeam 2k\n",
      "Number of samples: 582\n",
      "================================================================================\n",
      "\n",
      "\n",
      "Combining datasets...\n",
      "\n",
      "Original Dataset Distribution\n",
      "================================================================================\n",
      "Dataset                             Count   Percentage\n",
      "--------------------------------------------------------------------------------\n",
      "Aegis v2                           23,077       73.74%\n",
      "Gretel Safety Alignment v1          5,994       19.15%\n",
      "HarmfulTasks                        1,650        5.27%\n",
      "RedTeam 2k                            573        1.83%\n",
      "--------------------------------------------------------------------------------\n",
      "Total                              31,294      100.00%\n",
      "================================================================================\n",
      "\n",
      "Saving full dataset to ./workspace/training/dataset_cache/nemo_safety_blend_v0.2.2.jsonl...\n",
      "Full dataset saved with 31,294 samples\n",
      "\n",
      "Performing uniform sampling across categories...\n",
      "RedTeam 2k: 500 samples selected\n",
      "HarmfulTasks: 500 samples selected\n",
      "Gretel Safety Alignment v1: 500 samples selected\n",
      "Aegis v2: 500 samples selected\n",
      "\n",
      "Sampling Report\n",
      "================================================================================\n",
      "Original dataset size: 31,294\n",
      "Sampled dataset size: 2,000\n",
      "Sampling ratio: 6.39%\n",
      "Sampling method: uniform\n",
      "================================================================================\n",
      "\n",
      "Sampled Dataset Distribution\n",
      "================================================================================\n",
      "Dataset                             Count   Percentage\n",
      "--------------------------------------------------------------------------------\n",
      "RedTeam 2k                            500       25.00%\n",
      "HarmfulTasks                          500       25.00%\n",
      "Gretel Safety Alignment v1            500       25.00%\n",
      "Aegis v2                              500       25.00%\n",
      "--------------------------------------------------------------------------------\n",
      "Total                               2,000      100.00%\n",
      "================================================================================\n",
      "\n",
      "Saving sampled dataset to ./workspace/training/dataset_cache/nemo_safety_blend_v0.2.2_sampled_2000_uniform.jsonl\n",
      "Sampled dataset saved with 2,000 samples\n",
      "\n",
      "Total processing time: 10.21 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling from categories: 100%|██████████| 4/4 [00:00<00:00, 321.83it/s]\n"
     ]
    }
   ],
   "source": [
    "#os.chdir(f\"{BASE_DIR}/NeMo-Safety/notebooks\")\n",
    "result = subprocess.run([\n",
    "    'python3', 'safety_dataset_blend_generation.py',\n",
    "    '--filename', os.path.join(os.environ['DATASET_CACHE_DIR'], SAFETY_DATASET_NAME),\n",
    "    '--total_samples', '2000',\n",
    "    '--sampling_method', 'uniform',\n",
    "    '--cache_dir', os.environ['DATASET_CACHE_DIR']\n",
    "], check=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed9fda79",
   "metadata": {},
   "source": [
    "Download Llama Nemotron Post-training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8546dff5-4109-4e84-a335-c51a8d8af372",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading SFT/math/math_v1.1.jsonl...\n",
      "Total lines in file: 2225427\n",
      "Extracted 1000 random samples to ./workspace/training/dataset_cache/Llama-Nemotron-Post-Training-Dataset/math_v1.1.jsonl\n",
      "Downloading SFT/code/code_v1.1.jsonl...\n",
      "Total lines in file: 496206\n",
      "Extracted 1000 random samples to ./workspace/training/dataset_cache/Llama-Nemotron-Post-Training-Dataset/code_v1.1.jsonl\n",
      "Downloading SFT/chat/chat.jsonl...\n",
      "Total lines in file: 39792\n",
      "Extracted 1000 random samples to ./workspace/training/dataset_cache/Llama-Nemotron-Post-Training-Dataset/chat.jsonl\n",
      "Downloading SFT/science/science.jsonl...\n",
      "Total lines in file: 708920\n",
      "Extracted 1000 random samples to ./workspace/training/dataset_cache/Llama-Nemotron-Post-Training-Dataset/science.jsonl\n"
     ]
    }
   ],
   "source": [
    "files = [\n",
    "    \"SFT/math/math_v1.1.jsonl\",\n",
    "    \"SFT/code/code_v1.1.jsonl\",\n",
    "    \"SFT/chat/chat.jsonl\",\n",
    "    \"SFT/science/science.jsonl\"\n",
    "]\n",
    "\n",
    "LLAMA_NEMO_DIR = f\"{os.environ['DATASET_CACHE_DIR']}/Llama-Nemotron-Post-Training-Dataset\"\n",
    "Path(LLAMA_NEMO_DIR).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "for file in files:\n",
    "    print(f\"Downloading {file}...\")\n",
    "    downloaded_path = hf_hub_download(\n",
    "        repo_id=POST_TRAINING_DATASET_NAME,\n",
    "        filename=file,\n",
    "        repo_type='dataset',\n",
    "        cache_dir=os.environ['DATASET_CACHE_DIR']\n",
    "    )\n",
    "    \n",
    "    filename = Path(file).name\n",
    "    target_path = f\"{LLAMA_NEMO_DIR}/{filename}\"\n",
    "    \n",
    "    # Count lines and sample\n",
    "    with open(downloaded_path, 'r') as f:\n",
    "        total_lines = sum(1 for _ in f)\n",
    "    \n",
    "    print(f\"Total lines in file: {total_lines}\")\n",
    "    \n",
    "    if total_lines > 1000:\n",
    "        # Use shuf for random sampling\n",
    "        subprocess.run(['shuf', '-n', '1000', downloaded_path], stdout=open(target_path, 'w'), check=True)\n",
    "        print(f\"Extracted 1000 random samples to {target_path}\")\n",
    "    else:\n",
    "        shutil.copy2(downloaded_path, target_path)\n",
    "        print(f\"File has fewer than 1000 lines, copied all {total_lines} lines\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1771977",
   "metadata": {},
   "source": [
    "Combine safety and accuracy datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ff0fd393-241b-4200-a2ba-c75c03904626",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading safety dataset from ./workspace/training/dataset_cache/nemo_safety_blend_v0.2.2_sampled_2000_uniform.jsonl...\n",
      "Loaded 2000 samples from safety dataset\n",
      "\n",
      "Found 4 Llama-Nemotron files: ['./workspace/training/dataset_cache/Llama-Nemotron-Post-Training-Dataset/math_v1.1.jsonl', './workspace/training/dataset_cache/Llama-Nemotron-Post-Training-Dataset/code_v1.1.jsonl', './workspace/training/dataset_cache/Llama-Nemotron-Post-Training-Dataset/science.jsonl', './workspace/training/dataset_cache/Llama-Nemotron-Post-Training-Dataset/chat.jsonl']\n",
      "\n",
      "Loading ./workspace/training/dataset_cache/Llama-Nemotron-Post-Training-Dataset/math_v1.1.jsonl as 'math_v1'...\n",
      "Added 998/1000 items from math_v1\n",
      "\n",
      "Loading ./workspace/training/dataset_cache/Llama-Nemotron-Post-Training-Dataset/code_v1.1.jsonl as 'code_v1'...\n",
      "Added 882/1000 items from code_v1\n",
      "\n",
      "Loading ./workspace/training/dataset_cache/Llama-Nemotron-Post-Training-Dataset/science.jsonl as 'science'...\n",
      "Added 1000/1000 items from science\n",
      "\n",
      "Token Statistics:\n",
      "Total samples processed: 5000\n",
      "Samples skipped due to token limit: 120 (2.4%)\n",
      "Samples kept: 4880 (97.6%)\n",
      "\n",
      "Token counts by source:\n",
      "\n",
      "llama_nemo_code_v1:\n",
      "  Samples: 882 (17.6%)\n",
      "  Total tokens: 9,309,110\n",
      "  Average tokens per sample: 10554.5\n",
      "  Min tokens: 463\n",
      "  Max tokens: 19071\n",
      "  Samples skipped: 118 (11.8%)\n",
      "\n",
      "llama_nemo_math_v1:\n",
      "  Samples: 998 (20.0%)\n",
      "  Total tokens: 5,794,337\n",
      "  Average tokens per sample: 5805.9\n",
      "  Min tokens: 449\n",
      "  Max tokens: 16470\n",
      "  Samples skipped: 2 (0.2%)\n",
      "\n",
      "llama_nemo_science:\n",
      "  Samples: 1000 (20.0%)\n",
      "  Total tokens: 1,852,288\n",
      "  Average tokens per sample: 1852.3\n",
      "  Min tokens: 252\n",
      "  Max tokens: 8823\n",
      "  Samples skipped: 0 (0.0%)\n",
      "\n",
      "safety_dataset:\n",
      "  Samples: 2000 (40.0%)\n",
      "  Total tokens: 267,963\n",
      "  Average tokens per sample: 134.0\n",
      "  Min tokens: 1\n",
      "  Max tokens: 3284\n",
      "  Samples skipped: 0 (0.0%)\n",
      "\n",
      "Saving train dataset (4,734 samples) to ./workspace/training/dataset_cache/sft_data/train.jsonl...\n",
      "Saving validation dataset (146 samples) to ./workspace/training/dataset_cache/sft_data/val.jsonl...\n",
      "\n",
      "Final dataset statistics:\n",
      "Total samples processed: 5000\n",
      "Samples kept: 4880 (97.6%)\n",
      "Train samples: 4734 (97.0%)\n",
      "Validation samples: 146 (3.0%)\n",
      "\n",
      "Train set source distribution:\n",
      "safety_dataset: 1939 (41.0%)\n",
      "llama_nemo_science: 971 (20.5%)\n",
      "llama_nemo_math_v1: 965 (20.4%)\n",
      "llama_nemo_code_v1: 859 (18.1%)\n",
      "\n",
      "Validation set source distribution:\n",
      "safety_dataset: 61 (41.8%)\n",
      "llama_nemo_math_v1: 33 (22.6%)\n",
      "llama_nemo_science: 29 (19.9%)\n",
      "llama_nemo_code_v1: 23 (15.8%)\n",
      "\n",
      "Prompt Label Statistics:\n",
      "\n",
      "Label Distribution:\n",
      "unsafe: 1734 samples (86.7%)\n",
      "safe: 266 samples (13.3%)\n",
      "\n",
      "Category Distribution:\n",
      ": 214 samples\n",
      "criminal planning/confessions: 117 samples\n",
      "malicious use: 113 samples\n",
      "substance abuse and dangerous practices: 111 samples\n",
      "system risks: 106 samples\n",
      "information hazards: 105 samples\n",
      "misinformation and disinformation: 103 samples\n",
      "unlawful behaviors and activities: 103 samples\n",
      "security threats and cybercrimes: 102 samples\n",
      "societal risks: 95 samples\n",
      "hate speech and discrimination: 81 samples\n",
      "discrimination: 81 samples\n",
      "illegal activity: 74 samples\n",
      "needs caution: 72 samples\n",
      "hate speech: 60 samples\n",
      "violence: 58 samples\n",
      "tailored unlicensed advice: 57 samples\n",
      "hate/identity hate: 48 samples\n",
      "fraud: 40 samples\n",
      "harassment: 35 samples\n",
      "child abuse: 33 samples\n",
      "health consultation: 29 samples\n",
      "physical harm: 28 samples\n",
      "malware: 28 samples\n",
      "political sensitivity: 28 samples\n",
      "unethical behavior: 26 samples\n",
      "government decision: 23 samples\n",
      "profanity: 21 samples\n",
      "economic harm: 19 samples\n",
      "controlled/regulated substances: 18 samples\n",
      "bias: 17 samples\n",
      "sexual: 17 samples\n",
      "guns and illegal weapons: 17 samples\n",
      "animal abuse: 16 samples\n",
      "pii/privacy: 16 samples\n",
      "privacy violation: 15 samples\n",
      "unauthorized advice: 12 samples\n",
      "suicide and self harm: 10 samples\n",
      "other: 7 samples\n",
      "political/misinformation/conspiracy: 6 samples\n",
      "immoral/unethical: 5 samples\n",
      "sexual (minor): 4 samples\n",
      "threat: 3 samples\n",
      "fraud/deception: 2 samples\n",
      "high risk gov decision making: 1 samples\n",
      "\n",
      "Category Distribution by Label:\n",
      "\n",
      "SAFE prompts:\n",
      "  : 214 samples (80.5%)\n",
      "  needs caution: 49 samples (18.4%)\n",
      "  harassment: 2 samples (0.8%)\n",
      "  unauthorized advice: 2 samples (0.8%)\n",
      "  sexual: 1 samples (0.4%)\n",
      "  profanity: 1 samples (0.4%)\n",
      "  violence: 1 samples (0.4%)\n",
      "  hate/identity hate: 1 samples (0.4%)\n",
      "  criminal planning/confessions: 1 samples (0.4%)\n",
      "\n",
      "UNSAFE prompts:\n",
      "  criminal planning/confessions: 116 samples (6.7%)\n",
      "  malicious use: 113 samples (6.5%)\n",
      "  substance abuse and dangerous practices: 111 samples (6.4%)\n",
      "  system risks: 106 samples (6.1%)\n",
      "  information hazards: 105 samples (6.1%)\n",
      "  misinformation and disinformation: 103 samples (5.9%)\n",
      "  unlawful behaviors and activities: 103 samples (5.9%)\n",
      "  security threats and cybercrimes: 102 samples (5.9%)\n",
      "  societal risks: 95 samples (5.5%)\n",
      "  hate speech and discrimination: 81 samples (4.7%)\n",
      "  discrimination: 81 samples (4.7%)\n",
      "  illegal activity: 74 samples (4.3%)\n",
      "  hate speech: 60 samples (3.5%)\n",
      "  tailored unlicensed advice: 57 samples (3.3%)\n",
      "  violence: 57 samples (3.3%)\n",
      "  hate/identity hate: 47 samples (2.7%)\n",
      "  fraud: 40 samples (2.3%)\n",
      "  child abuse: 33 samples (1.9%)\n",
      "  harassment: 33 samples (1.9%)\n",
      "  health consultation: 29 samples (1.7%)\n",
      "  physical harm: 28 samples (1.6%)\n",
      "  malware: 28 samples (1.6%)\n",
      "  political sensitivity: 28 samples (1.6%)\n",
      "  unethical behavior: 26 samples (1.5%)\n",
      "  government decision: 23 samples (1.3%)\n",
      "  needs caution: 23 samples (1.3%)\n",
      "  profanity: 20 samples (1.2%)\n",
      "  economic harm: 19 samples (1.1%)\n",
      "  controlled/regulated substances: 18 samples (1.0%)\n",
      "  bias: 17 samples (1.0%)\n",
      "  guns and illegal weapons: 17 samples (1.0%)\n",
      "  animal abuse: 16 samples (0.9%)\n",
      "  sexual: 16 samples (0.9%)\n",
      "  pii/privacy: 16 samples (0.9%)\n",
      "  privacy violation: 15 samples (0.9%)\n",
      "  suicide and self harm: 10 samples (0.6%)\n",
      "  unauthorized advice: 10 samples (0.6%)\n",
      "  other: 7 samples (0.4%)\n",
      "  political/misinformation/conspiracy: 6 samples (0.3%)\n",
      "  immoral/unethical: 5 samples (0.3%)\n",
      "  sexual (minor): 4 samples (0.2%)\n",
      "  threat: 3 samples (0.2%)\n",
      "  fraud/deception: 2 samples (0.1%)\n",
      "  high risk gov decision making: 1 samples (0.1%)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args=['python3', 'combine_datasets.py', '--safety_file', './workspace/training/dataset_cache/nemo_safety_blend_v0.2.2_sampled_2000_uniform.jsonl', '--llama_nemo_dir', './workspace/training/dataset_cache/Llama-Nemotron-Post-Training-Dataset', '--output_dir', './workspace/training/dataset_cache/sft_data', '--val_split', '0.03', '--max_tokens', '16384', '--max_samples', '5000'], returncode=0)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "OUTPUT_DIR = f\"{os.environ['DATASET_CACHE_DIR']}/sft_data\"\n",
    "subprocess.run([\n",
    "    'python3', 'combine_datasets.py',\n",
    "    '--safety_file', f\"{os.environ['DATASET_CACHE_DIR']}/nemo_safety_blend_v0.2.2_sampled_2000_uniform.jsonl\", # TODO: Name change\n",
    "    '--llama_nemo_dir', LLAMA_NEMO_DIR,\n",
    "    '--output_dir', OUTPUT_DIR,\n",
    "    '--val_split', '0.03',\n",
    "    '--max_tokens', '16384',\n",
    "    '--max_samples', '5000'\n",
    "], check=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bdb206f0-bc57-479f-81b8-b833be66165b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train.jsonl  val.jsonl\n"
     ]
    }
   ],
   "source": [
    "!ls {OUTPUT_DIR}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "febe81b4-5add-45f6-8cd1-0a7d71f3175a",
   "metadata": {},
   "source": [
    "### Start vLLM Servers: Policy Model and Content Safety\n",
    "\n",
    "First, download the `nvidia/llama-3.1-nemoguard-8b-content-safety` model from Hugging Face."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2a646d0f-031c-4337-b8ac-91200b6aa99c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching 4 files: 100%|██████████| 4/4 [00:18<00:00,  4.64s/it]\n",
      "Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00, 103.87it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('./workspace/training/model//llama-3.1-nemoguard-8b-content-safety/tokenizer_config.json',\n",
       " './workspace/training/model//llama-3.1-nemoguard-8b-content-safety/special_tokens_map.json',\n",
       " './workspace/training/model//llama-3.1-nemoguard-8b-content-safety/tokenizer.json')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from peft import PeftModel\n",
    "\n",
    "# Load base model\n",
    "from peft import PeftModel\n",
    "from transformers import AutoModelForCausalLM\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"meta-llama/Llama-3.1-8B-Instruct\")\n",
    "base_model = AutoModelForCausalLM.from_pretrained(\"meta-llama/Meta-Llama-3.1-8B-Instruct\", torch_dtype=torch.bfloat16)\n",
    "model = PeftModel.from_pretrained(base_model, \"nvidia/llama-3.1-nemoguard-8b-content-safety\")\n",
    "merged_model = model.merge_and_unload()\n",
    "\n",
    "# Save merged model\n",
    "merged_model.save_pretrained(SAFETY_MODEL_PATH, torch_dtype=torch.bfloat16)\n",
    "tokenizer.save_pretrained(SAFETY_MODEL_PATH)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c834aca",
   "metadata": {},
   "source": [
    "Start one vLLM server for the policy model to train and another vLLM server with the content safety model to perform LLM-as-a-judge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dedaf55b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting policy model server...\n",
      "Starting safety model server...\n"
     ]
    }
   ],
   "source": [
    "os.environ.update({\n",
    "    'VLLM_ENGINE_ITERATION_TIMEOUT_S': '36000',\n",
    "    'VLLM_ALLOW_LONG_MAX_MODEL_LEN': '1',\n",
    "    'VLLM_HOST': '0.0.0.0',\n",
    "    'VLLM_TENSOR_PARALLEL_SIZE': '4',\n",
    "    'POLICY_MODEL_GPUS': '0,1,2,3',\n",
    "    'SAFETY_MODEL_GPUS': '4,5,6,7',\n",
    "    'TMPDIR': '/tmp' \n",
    "})\n",
    "\n",
    "print(\"Starting policy model server...\")\n",
    "policy_server = subprocess.Popen([\n",
    "    'python3', '-m', 'vllm.entrypoints.openai.api_server',\n",
    "    '--model', MODEL_NAME_OR_PATH,\n",
    "    '--trust-remote-code',\n",
    "    '--seed', '1',\n",
    "    '--host', os.environ['VLLM_HOST'],\n",
    "    '--port', '5000',\n",
    "    '--served-model-name', 'test-model',\n",
    "    '--enable-reasoning', \n",
    "    '--reasoning-parser', 'qwen3',\n",
    "    '--tensor-parallel-size', os.environ['VLLM_TENSOR_PARALLEL_SIZE'],\n",
    "    '--download-dir', os.environ['HF_HOME']\n",
    "], env={**os.environ, 'CUDA_VISIBLE_DEVICES': os.environ['POLICY_MODEL_GPUS']},\n",
    "   stdout=open(f\"{LOG_DIR}/vllm-server-model.log\", 'w'),\n",
    "   stderr=subprocess.STDOUT)\n",
    "\n",
    "print(\"Starting safety model server...\")\n",
    "safety_server = subprocess.Popen([\n",
    "    'python3', '-m', 'vllm.entrypoints.openai.api_server',\n",
    "    '--model', SAFETY_MODEL_PATH,\n",
    "    '--trust-remote-code',\n",
    "    '--seed', '1',\n",
    "    '--host', os.environ['VLLM_HOST'],\n",
    "    '--port', '6000',\n",
    "    '--served-model-name', 'safety-model',\n",
    "    '--tensor-parallel-size', os.environ['VLLM_TENSOR_PARALLEL_SIZE'],\n",
    "    '--download-dir', os.environ['HF_HOME']\n",
    "], env={**os.environ, 'CUDA_VISIBLE_DEVICES': os.environ['SAFETY_MODEL_GPUS']},\n",
    "   stdout=open(f\"{LOG_DIR}/vllm-server-safety.log\", 'w'),\n",
    "   stderr=subprocess.STDOUT)\n",
    "\n",
    "!sleep 120"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33541a90",
   "metadata": {},
   "source": [
    "### Generating On-Policy Data\n",
    "\n",
    "Using the combined dataset, the base model, and the content safety model, generate the on-policy data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e9f63bfd-c74f-4674-a1df-324b381cbbca",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating on-policy data...\n",
      "Data is Ready\n"
     ]
    }
   ],
   "source": [
    "CONCURRENCY = 16\n",
    "MAX_ATTEMPTS = 3\n",
    "BATCH_SIZE = 96\n",
    "\n",
    "MAX_TOKENS = 512\n",
    "TEMPERATURE = 0.7\n",
    "TOP_P = 0.9\n",
    "\n",
    "print(\"Generating on-policy data...\")\n",
    "for dataset_type in ['train', 'val']:\n",
    "    input_dataset = f\"{OUTPUT_DIR}/{dataset_type}.jsonl\"\n",
    "    output_file = f\"{OUTPUT_DIR}/{dataset_type}_on_policy_data.jsonl\"\n",
    "    DATASET_TYPE = dataset_type\n",
    "    subprocess.run([\n",
    "        'python3', 'generate_on_policy_data.py',\n",
    "        '--model_name', MODEL_NAME_OR_PATH,\n",
    "        '--safety_model', SAFETY_MODEL_NAME,\n",
    "        '--huggingface_token', os.environ['HF_TOKEN'],\n",
    "        '--vllm_host', os.environ['VLLM_HOST'],\n",
    "        '--vllm_model_port', '5000',\n",
    "        '--vllm_safety_port', '6000',\n",
    "        '--concurrency', str(CONCURRENCY),\n",
    "        '--input_dataset', input_dataset,\n",
    "        '--output', output_file,\n",
    "        '--batch_size', str(BATCH_SIZE),\n",
    "        '--max_tokens', str(MAX_TOKENS),\n",
    "        '--temperature', str(TEMPERATURE),\n",
    "        '--top_p', str(TOP_P)\n",
    "    ], stdout=open(f\"{LOG_DIR}/{DATASET_TYPE}_on-policy.log\", 'w'),\n",
    "                   stderr=subprocess.STDOUT)\n",
    "\n",
    "print(\"Data is Ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12cc0ab7",
   "metadata": {},
   "source": [
    "### Stop the vLLM Servers\n",
    "\n",
    "Run the following command to stop the vLLM servers. If you run them on terminals, press Ctrl+C to stop the vLLM servers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e5fcc89c-c256-4e65-84e5-2110b0a170b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args=['pkill', '-f', 'vllm.entrypoints.openai.api_server'], returncode=0)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cleanup vLLM servers\n",
    "subprocess.run(['pkill', '-f', 'vllm.entrypoints.openai.api_server'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ce784cb",
   "metadata": {},
   "source": [
    "### Fine-Tune the Model\n",
    "\n",
    "Use NeMo-RL to post-train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7e42fbf0-bd6d-480b-b56b-a35ef4a04bb8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running SFT...\n"
     ]
    },
    {
     "ename": "CalledProcessError",
     "evalue": "Command '['uv', 'run', 'python', 'examples/run_sft.py', '--config', '/ephemeral/workspace/workspace/NeMo-RL/deepseek_sft.yaml']' returned non-zero exit status 1.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mCalledProcessError\u001b[39m                        Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 12\u001b[39m\n\u001b[32m     10\u001b[39m os.environ[\u001b[33m\"\u001b[39m\u001b[33mCUDA_VISIBLE_DEVICES\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[33m\"\u001b[39m\u001b[33m0,1,2,3,4,5,6,7\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     11\u001b[39m \u001b[38;5;66;03m#os.chdir(\"../../NeMo-RL\")\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m \u001b[43msubprocess\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43muv\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mrun\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mpython\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mexamples/run_sft.py\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m     13\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m--config\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig_filepath\u001b[49m\n\u001b[32m     14\u001b[39m \u001b[43m               \u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m     15\u001b[39m \u001b[43m               \u001b[49m\u001b[43menv\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mos\u001b[49m\u001b[43m.\u001b[49m\u001b[43menviron\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mTMPDIR\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mos\u001b[49m\u001b[43m.\u001b[49m\u001b[43menviron\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mRAY_TMPDIR\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     16\u001b[39m \u001b[43m               \u001b[49m\u001b[43mstdout\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mMODEL_DIR\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m/sft.stdout\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mw\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     17\u001b[39m \u001b[43m               \u001b[49m\u001b[43mstderr\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mMODEL_DIR\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m/sft.stderr\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mw\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m               \u001b[49m\n\u001b[32m     18\u001b[39m \u001b[43m               \u001b[49m\u001b[43mcheck\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.12/subprocess.py:571\u001b[39m, in \u001b[36mrun\u001b[39m\u001b[34m(input, capture_output, timeout, check, *popenargs, **kwargs)\u001b[39m\n\u001b[32m    569\u001b[39m     retcode = process.poll()\n\u001b[32m    570\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m check \u001b[38;5;129;01mand\u001b[39;00m retcode:\n\u001b[32m--> \u001b[39m\u001b[32m571\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m CalledProcessError(retcode, process.args,\n\u001b[32m    572\u001b[39m                                  output=stdout, stderr=stderr)\n\u001b[32m    573\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m CompletedProcess(process.args, retcode, stdout, stderr)\n",
      "\u001b[31mCalledProcessError\u001b[39m: Command '['uv', 'run', 'python', 'examples/run_sft.py', '--config', '/ephemeral/workspace/workspace/NeMo-RL/deepseek_sft.yaml']' returned non-zero exit status 1."
     ]
    }
   ],
   "source": [
    "#os.chdir(\"/lustre/fsw/llmservice_nemo_mlops/users/ysuhara/work/gitlab/NeMo-Safety/notebooks\")\n",
    "#!ln -s `readlink -f workspace` /workspace/NeMo-RL/\n",
    "\n",
    "MODEL_DIR = os.path.abspath(f\"{BASE_DIR}/results/DeepSeek-R1-Distill-Llama-8B/\")\n",
    "!mkdir -p {MODEL_DIR}\n",
    "config_filepath = os.path.abspath(\"deepseek_sft.yaml\")\n",
    "\n",
    "print(\"Running SFT...\")\n",
    "# Set up model directory environment variable\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0,1,2,3,4,5,6,7\"\n",
    "#os.chdir(\"../../NeMo-RL\")\n",
    "subprocess.run(['uv', 'run', 'python', 'examples/run_sft.py', \n",
    "                '--config', config_filepath\n",
    "               ], \n",
    "               env={**os.environ, 'TMPDIR': os.environ['RAY_TMPDIR']},\n",
    "               stdout=open(f\"{MODEL_DIR}/sft.stdout\", 'w'),\n",
    "               stderr=open(f\"{MODEL_DIR}/sft.stderr\", 'w'),               \n",
    "               check=True)\n",
    "\n",
    "# !TMPDIR=$RAY_TMPDIR uv run python examples/run_sft.py --config {config_filepath} > {MODEL_DIR}/sft_log.out 2> {MODEL_DIR}/sft_log.err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bf8be7fe-c7e1-4054-8957-1ca79133c949",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/ephemeral/workspace/workspace/NeMo-RL/workspace/training/results/DeepSeek-R1-Distill-Llama-8B\n"
     ]
    }
   ],
   "source": [
    "!echo {MODEL_DIR}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "829574ec-cd8b-40a1-b555-30099669d13f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running SFT...\n",
      "Traceback (most recent call last):\n",
      "  File \"/ephemeral/workspace/workspace/NeMo-RL/examples/run_sft.py\", line 218, in <module>\n",
      "    main()\n",
      "  File \"/ephemeral/workspace/workspace/NeMo-RL/examples/run_sft.py\", line 159, in main\n",
      "    config = load_config(args.config)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/ephemeral/workspace/workspace/NeMo-RL/nemo_rl/utils/config.py\", line 137, in load_config\n",
      "    return load_config_with_inheritance(config_path)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/ephemeral/workspace/workspace/NeMo-RL/nemo_rl/utils/config.py\", line 48, in load_config_with_inheritance\n",
      "    config = OmegaConf.load(config_path)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/ephemeral/workspace/workspace/NeMo-RL/.venv/lib/python3.12/site-packages/omegaconf/omegaconf.py\", line 189, in load\n",
      "    with io.open(os.path.abspath(file_), \"r\", encoding=\"utf-8\") as f:\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "FileNotFoundError: [Errno 2] No such file or directory: '/ephemeral/workspace/workspace/NeMo-RL/{config_filepath}'\n"
     ]
    }
   ],
   "source": [
    "MODEL_DIR = os.path.abspath(f\"{BASE_DIR}/results/DeepSeek-R1-Distill-Llama-8B/\")\n",
    "!mkdir -p {MODEL_DIR}\n",
    "config_filepath = os.path.abspath(\"deepseek_sft.yaml\")\n",
    "\n",
    "print(\"Running SFT...\")\n",
    "\n",
    "!TMPDIR=$RAY_TMPDIR uv run python examples/run_sft.py --config {config_filepath} # > {MODEL_DIR}/sft_log.out 2> {MODEL_DIR}/sft_log.err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e19bee21-d5a0-499e-af11-6d6d45275629",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/ephemeral/workspace/workspace/NeMo-Safety/notebooks\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08d3f900",
   "metadata": {},
   "source": [
    "Convert the checkpoints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a57c51b6-5765-49ec-bb1d-69d58527c234",
   "metadata": {},
   "outputs": [],
   "source": [
    "CHECKPOINT_DIR = f\"{BASE_DIR}/results/DeepSeek-R1-Distill-Llama-8B/step_25\"\n",
    "DCP_CKPT_PATH = f\"{CHECKPOINT_DIR}/policy/weights/\"\n",
    "CONFIG_PATH = f\"{CHECKPOINT_DIR}/config.yaml\"\n",
    "HF_CKPT_PATH = f\"{MODEL_DIR}/DeepSeek-R1-Distill-Llama-8B-Safety-Trained\"\n",
    "\n",
    "print(\"Converting checkpoint...\")\n",
    "#os.chdir(f\"{BASE_DIR}/NeMo-RL\")\n",
    "os.chdir(f\"/workspace/NeMo-RL\")\n",
    "subprocess.run([\n",
    "    'uv', 'run', 'examples/convert_dcp_to_hf.py',\n",
    "    '--config', CONFIG_PATH,\n",
    "    '--dcp-ckpt-path', DCP_CKPT_PATH,\n",
    "    '--hf-ckpt-path', HF_CKPT_PATH\n",
    "], check=True)\n",
    "\n",
    "# Verify conversion\n",
    "if Path(f\"{HF_CKPT_PATH}/pytorch_model.bin\").exists() and Path(f\"{HF_CKPT_PATH}/config.json\").exists():\n",
    "    print(\"Conversion successful!\")\n",
    "    print(f\"The HuggingFace model is now available at: {HF_CKPT_PATH}\")\n",
    "else:\n",
    "    print(\"Conversion may have failed. Please check the output.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d82a515-2a5a-4037-8096-d3aa6b2e1a8e",
   "metadata": {},
   "source": [
    "### Next Steps\n",
    "\n",
    "You used post-training to improve the safety of the model, retained the accuracy of the original model, and saved the checkpoints.\n",
    "\n",
    "The next step is to [evaluate the safety and accuracy of the model](./Step3_Post_Training_Eval.ipynb)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
