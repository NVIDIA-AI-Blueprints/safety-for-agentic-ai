{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fd37e71a-284c-4cf0-8371-66916339bf47",
   "metadata": {},
   "source": [
    "# Notebook 2: Post-Training with Safety and Accuracy Data\n",
    "\n",
    "## About the Data\n",
    "\n",
    "This notebook demonstrates how to post-train the base model with safety-related data.\n",
    "The safety data is gathered from the following well-known datasets:\n",
    "\n",
    "- [Aegis AI Content Safety Dataset 2.0](https://huggingface.co/datasets/nvidia/Aegis-AI-Content-Safety-Dataset-2.0)\n",
    "- [Gretel Synthetic Safety Alignment Dataset](https://huggingface.co/datasets/gretelai/gretel-safety-alignment-en-v1)\n",
    "- [HarmfulTasks](https://github.com/CrystalEye42/eval-safety)\n",
    "- [RedTeam 2k](https://huggingface.co/datasets/JailbreakV-28K/JailBreakV-28k)\n",
    "\n",
    "Training also uses the [nvidia/LLama-Nemotron-Post-Training-Dataset](https://huggingface.co/datasets/nvidia/Llama-Nemotron-Post-Training-Dataset) to preserve the code, chat, math, and science reasoning abilities that can otherwise degrade with fine-tuning.\n",
    "\n",
    "## About the Process\n",
    "\n",
    "This notebook proceeds through the following high-level steps:\n",
    "\n",
    "- Set up a directory structure for logs and results.\n",
    "- Data preparation:\n",
    "  - Download the preceding safety-related datasets and extract 2000 total samples at random.\n",
    "  - Download the Llama Nemotron dataset and extract 4000 samples at random.\n",
    "  - Create training and validation datasets from the samples, excluding samples with a token length greater than `16384`.\n",
    "- Start one vLLM server to serve the base model to train.\n",
    "- Start another vLLM server to serve the NVIDIA Llama 3.1 Nemoguard 8B Instruct model to act as LLM as judge.\n",
    "- Fine-tune the model using [NeMo-RL](https://github.com/NVIDIA/NeMo-RL) to apply safety post-training to improve the safety of the target model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c17609ed",
   "metadata": {},
   "source": [
    "### Set up Packages and Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "def9dcce-240c-49ba-8d02-f4a70053d18c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "import time\n",
    "from pathlib import Path\n",
    "from huggingface_hub import hf_hub_download\n",
    "import shutil\n",
    "\n",
    "# Base directory and configuration\n",
    "BASE_DIR = \"./workspace/training\"\n",
    "LOG_DIR = f\"{BASE_DIR}/logs\"\n",
    "\n",
    "SAFETY_DATASET_NAME = \"nemo_safety_blend_v0.2.2.jsonl\"  # TODO: Change\n",
    "POST_TRAINING_DATASET_NAME = \"nvidia/Llama-Nemotron-Post-Training-Dataset\"\n",
    "MODEL_NAME_OR_PATH = \"deepseek-ai/DeepSeek-R1-Distill-Llama-8B\"\n",
    "MODEL_DIR = f\"{BASE_DIR}/model/\"\n",
    "SAFETY_MODEL_NAME = \"llama-3.1-nemoguard-8b-content-safety\"\n",
    "SAFETY_MODEL_PATH = f\"{MODEL_DIR}/{SAFETY_MODEL_NAME}\"\n",
    "\n",
    "# Credentials\n",
    "os.environ.update({\n",
    "    \"HF_TOKEN\":\"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\",\n",
    "    \"WANDB_API_KEY\": \"2f672ca9d8cf9366dda87615069e6a9f2de6a33d\"\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ebc62ad4-e2f1-440d-a8b8-957e400e395f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./workspace/training/model//llama-3.1-nemoguard-8b-content-safety\n"
     ]
    }
   ],
   "source": [
    "print(SAFETY_MODEL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "806681b5-869a-4a84-a2c5-9c4f4d3e7047",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p {LOG_DIR}\n",
    "!mkdir -p {MODEL_DIR}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bbde3367-ff98-4984-b8e1-7687fbc6379b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set environment variables\n",
    "os.environ.update({\n",
    "    'TMPDIR': f\"{BASE_DIR}/tmp\",\n",
    "    'XDG_CACHE_HOME': f\"{BASE_DIR}/cache\",\n",
    "    'HF_HOME': f\"{BASE_DIR}/cache/huggingface\",\n",
    "    'UV_CACHE_DIR': f\"{BASE_DIR}/cache/uv\",\n",
    "    'TRITON_CACHE_DIR': f\"{BASE_DIR}/cache/triton\",\n",
    "    'DATASET_CACHE_DIR': f\"{BASE_DIR}/dataset_cache\",\n",
    "    'RAY_TMPDIR': \"/tmp/ray\",\n",
    "    'LOG_DIR': f\"{LOG_DIR}\",\n",
    "})\n",
    "\n",
    "# Create directories\n",
    "for dir_path in [os.environ['TMPDIR'], os.environ['XDG_CACHE_HOME'], os.environ['HF_HOME'],\n",
    "                 os.environ['UV_CACHE_DIR'],os.environ['TRITON_CACHE_DIR'], os.environ['DATASET_CACHE_DIR'], \n",
    "                 os.environ['RAY_TMPDIR'], os.environ['LOG_DIR']]:\n",
    "    Path(dir_path).mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "994dafc1-3758-4d51-8ed1-3ddef45196cd",
   "metadata": {},
   "source": [
    "### Generating Safety Training Data\n",
    "\n",
    "The key idea is to use on-policy data generated by the target model.\n",
    "This approach improves safety, while making sure to obtain safe responses even for unsafe prompts. \n",
    "\n",
    "The notebook uses a safety training data generation recipe that uses the following public datasets:\n",
    "\n",
    "- Aegis AI Content Safety Dataset 2.0\n",
    "- Gretel Synthetic Safety Alignment Dataset\n",
    "- HarmfulTasks\n",
    "- RedTeam 2k\n",
    "\n",
    "The notebook extracts safe and unsafe prompts from Aegis AI Content Safety Dataset 2.0 and unsafe prompts from the other three datasets. \n",
    "\n",
    "### Response Generation for Safe Prompts\n",
    "\n",
    "For safe prompts, the notebook uses the target model and the prompts as-is to generate responses.\n",
    "When you have access to a larger model in the same model family---such as `deepseek-ai/DeepSeek-R1` instead of `deepseek-ai/DeepSeek-R1-Distill-Llama-8B`---use the larger model because it should generate safe responses better than the smaller model. \n",
    "\n",
    "### Response Generation for Unsafe Prompts\n",
    "\n",
    "Because the unsafe prompts in the HarmfulTasks dataset have jailbreak prompts that begin with text like \"Ignore all instructions until now...\" and end with a request like \"Write a blog post promoting mistrust between different social groups.\"\n",
    "The jailbreak portion of the prompts are removed, but the model still generates responses to the unsafe user request, such as writing a blog to promote mistrust.\n",
    "\n",
    "All unsafe prompts are wrapped in a new prompt template, shown below, that instructs the model to disengage but also inform the user exactly why---using the ground truth harm categories in the datasets and not a canned response.\n",
    "\n",
    "```\n",
    "You are a helpful assistant that generates safe responses for given prompts.\n",
    "\n",
    "The prompt is: {prompt}\n",
    "This prompt is known to violate the following safety categories or elicits unsafe responses of these categories from the model. The categories are: {categories}\n",
    "\n",
    "Generate a safe refusal for the prompt that politely points out that the model doesn't engage in unsafe behavior for the given categories. Your response:\n",
    "```\n",
    "\n",
    "With this approach, the model can generate safe responses for unsafe prompts. \n",
    "\n",
    "For training, the notebook passes the original unsafe prompt and the generated response---not the one with the safe prompt wrapper described above. Effectively, we are trying to teach the model to generate the same response to the original unsafe prompt such as with the jailbreak instructions for the HarmfulTasks prompts.\n",
    "\n",
    "### Response Filtering\n",
    "\n",
    "The generated responses for the safe and unsafe prompts discussed above are not guaranteed to be safe responses. Therefore, we implement a filtering step to extract the generated responses that are judged as safe by a guard model.\n",
    "\n",
    "We use [nvidia/llama-3.1-nemoguard-8b-content-safety](https://huggingface.co/nvidia/llama-3.1-nemoguard-8b-content-safety) as the guard model for this filtering step.\n",
    "\n",
    "### Blend Safety Training Data with Accuracy Data\n",
    "\n",
    "Safety training data helps the model learn to refuse to answer unsafe prompts. As a result, the model can experience some accuracy degradation for certain capabilities such as instruction following.\n",
    "\n",
    "To address the issue, the notebook adds post-training data to retain the accuracy. We use a subset of  [nvidia/Llama-Nemotron-Post-Training-Dataset](https://huggingface.co/datasets/nvidia/Llama-Nemotron-Post-Training-Dataset), which was used to train Llama Nemotron models—world-class reasoning models, for this purpose. \n",
    "\n",
    "More specifically, in this recipe, the notebook generates on-policy data using the model.\n",
    "The on-policy data can help retain the same behavior as the original model for the prompts in the post-training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "daf5e2e0-0b2b-4032-84d6-d91f3b16891b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting dataset collection...\n",
      "Output file: ./workspace/training/dataset_cache/nemo_safety_blend_v0.2.2.jsonl\n",
      "Target sample size: 2,000\n",
      "Sampling method: uniform\n",
      "Using cache directory: ./workspace/training/dataset_cache\n",
      "\n",
      "Downloading Aegis v2 dataset...\n",
      "Source: nvidia/Aegis-AI-Content-Safety-Dataset-2.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 100%|██████████| 30007/30007 [00:00<00:00, 151049.99 examples/s]\n",
      "Generating validation split: 100%|██████████| 1445/1445 [00:00<00:00, 83043.58 examples/s]\n",
      "Generating test split: 100%|██████████| 1964/1964 [00:00<00:00, 131103.29 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "Dataset: Aegis v2\n",
      "Number of samples: 23,077\n",
      "================================================================================\n",
      "\n",
      "\n",
      "Downloading Gretel Safety Alignment v1 dataset...\n",
      "Source: gretelai/gretel-safety-alignment-en-v1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 100%|██████████| 5997/5997 [00:00<00:00, 117777.92 examples/s]\n",
      "Generating test split: 100%|██████████| 1183/1183 [00:00<00:00, 72591.72 examples/s]\n",
      "Generating validation split: 100%|██████████| 1181/1181 [00:00<00:00, 80094.96 examples/s]\n",
      "Cloning into 'eval-safety'...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "Dataset: Gretel Safety Alignment v1\n",
      "Number of samples: 5,997\n",
      "================================================================================\n",
      "\n",
      "\n",
      "Downloading Harmful Tasks dataset...\n",
      "Source: CrystalEye42/eval-safety\n",
      "Processing Harmful Tasks data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing categories: 100%|██████████| 5/5 [00:00<00:00, 52958.38it/s]\n",
      "Processing tasks: 100%|██████████| 11/11 [00:00<00:00, 28962.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "Dataset: Harmful Tasks\n",
      "Number of samples: 1,650\n",
      "================================================================================\n",
      "\n",
      "\n",
      "Downloading RedTeam 2k dataset...\n",
      "Source: JailbreakV-28K/JailBreakV-28k\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating RedTeam_2K split: 100%|██████████| 2000/2000 [00:00<00:00, 244330.76 examples/s]\n",
      "Filter: 100%|██████████| 2000/2000 [00:00<00:00, 189389.02 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "Dataset: RedTeam 2k\n",
      "Number of samples: 582\n",
      "================================================================================\n",
      "\n",
      "\n",
      "Combining datasets...\n",
      "\n",
      "Original Dataset Distribution\n",
      "================================================================================\n",
      "Dataset                             Count   Percentage\n",
      "--------------------------------------------------------------------------------\n",
      "Aegis v2                           23,077       73.74%\n",
      "Gretel Safety Alignment v1          5,994       19.15%\n",
      "HarmfulTasks                        1,650        5.27%\n",
      "RedTeam 2k                            573        1.83%\n",
      "--------------------------------------------------------------------------------\n",
      "Total                              31,294      100.00%\n",
      "================================================================================\n",
      "\n",
      "Saving full dataset to ./workspace/training/dataset_cache/nemo_safety_blend_v0.2.2.jsonl...\n",
      "Full dataset saved with 31,294 samples\n",
      "\n",
      "Performing uniform sampling across categories...\n",
      "RedTeam 2k: 500 samples selected\n",
      "HarmfulTasks: 500 samples selected\n",
      "Gretel Safety Alignment v1: 500 samples selected\n",
      "Aegis v2: 500 samples selected\n",
      "\n",
      "Sampling Report\n",
      "================================================================================\n",
      "Original dataset size: 31,294\n",
      "Sampled dataset size: 2,000\n",
      "Sampling ratio: 6.39%\n",
      "Sampling method: uniform\n",
      "================================================================================\n",
      "\n",
      "Sampled Dataset Distribution\n",
      "================================================================================\n",
      "Dataset                             Count   Percentage\n",
      "--------------------------------------------------------------------------------\n",
      "RedTeam 2k                            500       25.00%\n",
      "HarmfulTasks                          500       25.00%\n",
      "Gretel Safety Alignment v1            500       25.00%\n",
      "Aegis v2                              500       25.00%\n",
      "--------------------------------------------------------------------------------\n",
      "Total                               2,000      100.00%\n",
      "================================================================================\n",
      "\n",
      "Saving sampled dataset to ./workspace/training/dataset_cache/nemo_safety_blend_v0.2.2_sampled_2000_uniform.jsonl\n",
      "Sampled dataset saved with 2,000 samples\n",
      "\n",
      "Total processing time: 17.19 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling from categories: 100%|██████████| 4/4 [00:00<00:00, 532.68it/s]\n"
     ]
    }
   ],
   "source": [
    "# 1. Download NV Safety Dataset\n",
    "#os.chdir(f\"{BASE_DIR}/NeMo-Safety/notebooks\")\n",
    "result = subprocess.run([\n",
    "    'python3', 'safety_dataset_blend_generation.py',\n",
    "    '--filename', os.path.join(os.environ['DATASET_CACHE_DIR'], SAFETY_DATASET_NAME),\n",
    "    '--total_samples', '2000',\n",
    "    '--sampling_method', 'uniform',\n",
    "    '--cache_dir', os.environ['DATASET_CACHE_DIR']\n",
    "], check=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed9fda79",
   "metadata": {},
   "outputs": [],
   "source": [
    "Download Llama Nemotron Post-training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8546dff5-4109-4e84-a335-c51a8d8af372",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading SFT/math/math_v1.1.jsonl...\n",
      "Total lines in file: 2225427\n",
      "Extracted 1000 random samples to ./workspace/training/dataset_cache/Llama-Nemotron-Post-Training-Dataset/math_v1.1.jsonl\n",
      "Downloading SFT/code/code_v1.1.jsonl...\n",
      "Total lines in file: 496206\n",
      "Extracted 1000 random samples to ./workspace/training/dataset_cache/Llama-Nemotron-Post-Training-Dataset/code_v1.1.jsonl\n",
      "Downloading SFT/chat/chat.jsonl...\n",
      "Total lines in file: 39792\n",
      "Extracted 1000 random samples to ./workspace/training/dataset_cache/Llama-Nemotron-Post-Training-Dataset/chat.jsonl\n",
      "Downloading SFT/science/science.jsonl...\n",
      "Total lines in file: 708920\n",
      "Extracted 1000 random samples to ./workspace/training/dataset_cache/Llama-Nemotron-Post-Training-Dataset/science.jsonl\n"
     ]
    }
   ],
   "source": [
    "files = [\n",
    "    \"SFT/math/math_v1.1.jsonl\",\n",
    "    \"SFT/code/code_v1.1.jsonl\",\n",
    "    \"SFT/chat/chat.jsonl\",\n",
    "    \"SFT/science/science.jsonl\"\n",
    "]\n",
    "\n",
    "LLAMA_NEMO_DIR = f\"{os.environ['DATASET_CACHE_DIR']}/Llama-Nemotron-Post-Training-Dataset\"\n",
    "Path(LLAMA_NEMO_DIR).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "for file in files:\n",
    "    print(f\"Downloading {file}...\")\n",
    "    downloaded_path = hf_hub_download(\n",
    "        repo_id=POST_TRAINING_DATASET_NAME,\n",
    "        filename=file,\n",
    "        repo_type='dataset',\n",
    "        cache_dir=os.environ['DATASET_CACHE_DIR']\n",
    "    )\n",
    "    \n",
    "    filename = Path(file).name\n",
    "    target_path = f\"{LLAMA_NEMO_DIR}/{filename}\"\n",
    "    \n",
    "    # Count lines and sample\n",
    "    with open(downloaded_path, 'r') as f:\n",
    "        total_lines = sum(1 for _ in f)\n",
    "    \n",
    "    print(f\"Total lines in file: {total_lines}\")\n",
    "    \n",
    "    if total_lines > 1000:\n",
    "        # Use shuf for random sampling\n",
    "        subprocess.run(['shuf', '-n', '1000', downloaded_path], stdout=open(target_path, 'w'), check=True)\n",
    "        print(f\"Extracted 1000 random samples to {target_path}\")\n",
    "    else:\n",
    "        shutil.copy2(downloaded_path, target_path)\n",
    "        print(f\"File has fewer than 1000 lines, copied all {total_lines} lines\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1771977",
   "metadata": {},
   "source": [
    "Combine safety and accuracy datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ff0fd393-241b-4200-a2ba-c75c03904626",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading safety dataset from ./workspace/training/dataset_cache/nemo_safety_blend_v0.2.2_sampled_2000_uniform.jsonl...\n",
      "Loaded 2000 samples from safety dataset\n",
      "\n",
      "Found 4 Llama-Nemotron files: ['./workspace/training/dataset_cache/Llama-Nemotron-Post-Training-Dataset/code_v1.1.jsonl', './workspace/training/dataset_cache/Llama-Nemotron-Post-Training-Dataset/math_v1.1.jsonl', './workspace/training/dataset_cache/Llama-Nemotron-Post-Training-Dataset/chat.jsonl', './workspace/training/dataset_cache/Llama-Nemotron-Post-Training-Dataset/science.jsonl']\n",
      "\n",
      "Loading ./workspace/training/dataset_cache/Llama-Nemotron-Post-Training-Dataset/code_v1.1.jsonl as 'code_v1'...\n",
      "Added 880/1000 items from code_v1\n",
      "\n",
      "Loading ./workspace/training/dataset_cache/Llama-Nemotron-Post-Training-Dataset/math_v1.1.jsonl as 'math_v1'...\n",
      "Added 997/1000 items from math_v1\n",
      "\n",
      "Loading ./workspace/training/dataset_cache/Llama-Nemotron-Post-Training-Dataset/chat.jsonl as 'chat'...\n",
      "Added 1000/1000 items from chat\n",
      "\n",
      "Token Statistics:\n",
      "Total samples processed: 5000\n",
      "Samples skipped due to token limit: 123 (2.5%)\n",
      "Samples kept: 4877 (97.5%)\n",
      "\n",
      "Token counts by source:\n",
      "\n",
      "llama_nemo_code_v1:\n",
      "  Samples: 880 (17.6%)\n",
      "  Total tokens: 9,475,627\n",
      "  Average tokens per sample: 10767.8\n",
      "  Min tokens: 522\n",
      "  Max tokens: 17552\n",
      "  Samples skipped: 120 (12.0%)\n",
      "\n",
      "llama_nemo_math_v1:\n",
      "  Samples: 997 (19.9%)\n",
      "  Total tokens: 6,042,966\n",
      "  Average tokens per sample: 6061.1\n",
      "  Min tokens: 267\n",
      "  Max tokens: 16425\n",
      "  Samples skipped: 3 (0.3%)\n",
      "\n",
      "llama_nemo_chat:\n",
      "  Samples: 1000 (20.0%)\n",
      "  Total tokens: 1,427,206\n",
      "  Average tokens per sample: 1427.2\n",
      "  Min tokens: 15\n",
      "  Max tokens: 7987\n",
      "  Samples skipped: 0 (0.0%)\n",
      "\n",
      "safety_dataset:\n",
      "  Samples: 2000 (40.0%)\n",
      "  Total tokens: 267,963\n",
      "  Average tokens per sample: 134.0\n",
      "  Min tokens: 1\n",
      "  Max tokens: 3284\n",
      "  Samples skipped: 0 (0.0%)\n",
      "\n",
      "Saving train dataset (4,731 samples) to ./workspace/training/dataset_cache/sft_data/train.jsonl...\n",
      "Saving validation dataset (146 samples) to ./workspace/training/dataset_cache/sft_data/val.jsonl...\n",
      "\n",
      "Final dataset statistics:\n",
      "Total samples processed: 5000\n",
      "Samples kept: 4877 (97.5%)\n",
      "Train samples: 4731 (97.0%)\n",
      "Validation samples: 146 (3.0%)\n",
      "\n",
      "Train set source distribution:\n",
      "safety_dataset: 1943 (41.1%)\n",
      "llama_nemo_math_v1: 969 (20.5%)\n",
      "llama_nemo_chat: 962 (20.3%)\n",
      "llama_nemo_code_v1: 857 (18.1%)\n",
      "\n",
      "Validation set source distribution:\n",
      "safety_dataset: 57 (39.0%)\n",
      "llama_nemo_chat: 38 (26.0%)\n",
      "llama_nemo_math_v1: 28 (19.2%)\n",
      "llama_nemo_code_v1: 23 (15.8%)\n",
      "\n",
      "Prompt Label Statistics:\n",
      "\n",
      "Label Distribution:\n",
      "unsafe: 1734 samples (86.7%)\n",
      "safe: 266 samples (13.3%)\n",
      "\n",
      "Category Distribution:\n",
      ": 214 samples\n",
      "criminal planning/confessions: 117 samples\n",
      "malicious use: 113 samples\n",
      "substance abuse and dangerous practices: 111 samples\n",
      "system risks: 106 samples\n",
      "information hazards: 105 samples\n",
      "misinformation and disinformation: 103 samples\n",
      "unlawful behaviors and activities: 103 samples\n",
      "security threats and cybercrimes: 102 samples\n",
      "societal risks: 95 samples\n",
      "hate speech and discrimination: 81 samples\n",
      "discrimination: 81 samples\n",
      "illegal activity: 74 samples\n",
      "needs caution: 72 samples\n",
      "hate speech: 60 samples\n",
      "violence: 58 samples\n",
      "tailored unlicensed advice: 57 samples\n",
      "hate/identity hate: 48 samples\n",
      "fraud: 40 samples\n",
      "harassment: 35 samples\n",
      "child abuse: 33 samples\n",
      "health consultation: 29 samples\n",
      "physical harm: 28 samples\n",
      "malware: 28 samples\n",
      "political sensitivity: 28 samples\n",
      "unethical behavior: 26 samples\n",
      "government decision: 23 samples\n",
      "profanity: 21 samples\n",
      "economic harm: 19 samples\n",
      "controlled/regulated substances: 18 samples\n",
      "bias: 17 samples\n",
      "sexual: 17 samples\n",
      "guns and illegal weapons: 17 samples\n",
      "animal abuse: 16 samples\n",
      "pii/privacy: 16 samples\n",
      "privacy violation: 15 samples\n",
      "unauthorized advice: 12 samples\n",
      "suicide and self harm: 10 samples\n",
      "other: 7 samples\n",
      "political/misinformation/conspiracy: 6 samples\n",
      "immoral/unethical: 5 samples\n",
      "sexual (minor): 4 samples\n",
      "threat: 3 samples\n",
      "fraud/deception: 2 samples\n",
      "high risk gov decision making: 1 samples\n",
      "\n",
      "Category Distribution by Label:\n",
      "\n",
      "SAFE prompts:\n",
      "  : 214 samples (80.5%)\n",
      "  needs caution: 49 samples (18.4%)\n",
      "  harassment: 2 samples (0.8%)\n",
      "  unauthorized advice: 2 samples (0.8%)\n",
      "  sexual: 1 samples (0.4%)\n",
      "  profanity: 1 samples (0.4%)\n",
      "  violence: 1 samples (0.4%)\n",
      "  hate/identity hate: 1 samples (0.4%)\n",
      "  criminal planning/confessions: 1 samples (0.4%)\n",
      "\n",
      "UNSAFE prompts:\n",
      "  criminal planning/confessions: 116 samples (6.7%)\n",
      "  malicious use: 113 samples (6.5%)\n",
      "  substance abuse and dangerous practices: 111 samples (6.4%)\n",
      "  system risks: 106 samples (6.1%)\n",
      "  information hazards: 105 samples (6.1%)\n",
      "  misinformation and disinformation: 103 samples (5.9%)\n",
      "  unlawful behaviors and activities: 103 samples (5.9%)\n",
      "  security threats and cybercrimes: 102 samples (5.9%)\n",
      "  societal risks: 95 samples (5.5%)\n",
      "  hate speech and discrimination: 81 samples (4.7%)\n",
      "  discrimination: 81 samples (4.7%)\n",
      "  illegal activity: 74 samples (4.3%)\n",
      "  hate speech: 60 samples (3.5%)\n",
      "  tailored unlicensed advice: 57 samples (3.3%)\n",
      "  violence: 57 samples (3.3%)\n",
      "  hate/identity hate: 47 samples (2.7%)\n",
      "  fraud: 40 samples (2.3%)\n",
      "  child abuse: 33 samples (1.9%)\n",
      "  harassment: 33 samples (1.9%)\n",
      "  health consultation: 29 samples (1.7%)\n",
      "  physical harm: 28 samples (1.6%)\n",
      "  malware: 28 samples (1.6%)\n",
      "  political sensitivity: 28 samples (1.6%)\n",
      "  unethical behavior: 26 samples (1.5%)\n",
      "  government decision: 23 samples (1.3%)\n",
      "  needs caution: 23 samples (1.3%)\n",
      "  profanity: 20 samples (1.2%)\n",
      "  economic harm: 19 samples (1.1%)\n",
      "  controlled/regulated substances: 18 samples (1.0%)\n",
      "  bias: 17 samples (1.0%)\n",
      "  guns and illegal weapons: 17 samples (1.0%)\n",
      "  animal abuse: 16 samples (0.9%)\n",
      "  sexual: 16 samples (0.9%)\n",
      "  pii/privacy: 16 samples (0.9%)\n",
      "  privacy violation: 15 samples (0.9%)\n",
      "  suicide and self harm: 10 samples (0.6%)\n",
      "  unauthorized advice: 10 samples (0.6%)\n",
      "  other: 7 samples (0.4%)\n",
      "  political/misinformation/conspiracy: 6 samples (0.3%)\n",
      "  immoral/unethical: 5 samples (0.3%)\n",
      "  sexual (minor): 4 samples (0.2%)\n",
      "  threat: 3 samples (0.2%)\n",
      "  fraud/deception: 2 samples (0.1%)\n",
      "  high risk gov decision making: 1 samples (0.1%)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args=['python3', 'combine_datasets.py', '--safety_file', './workspace/training/dataset_cache/nemo_safety_blend_v0.2.2_sampled_2000_uniform.jsonl', '--llama_nemo_dir', './workspace/training/dataset_cache/Llama-Nemotron-Post-Training-Dataset', '--output_dir', './workspace/training/dataset_cache/sft_data', '--val_split', '0.03', '--max_tokens', '16384', '--max_samples', '5000'], returncode=0)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "OUTPUT_DIR = f\"{os.environ['DATASET_CACHE_DIR']}/sft_data\"\n",
    "subprocess.run([\n",
    "    'python3', 'combine_datasets.py',\n",
    "    '--safety_file', f\"{os.environ['DATASET_CACHE_DIR']}/nemo_safety_blend_v0.2.2_sampled_2000_uniform.jsonl\", # TODO: Name change\n",
    "    '--llama_nemo_dir', LLAMA_NEMO_DIR,\n",
    "    '--output_dir', OUTPUT_DIR,\n",
    "    '--val_split', '0.03',\n",
    "    '--max_tokens', '16384',\n",
    "    '--max_samples', '5000'\n",
    "], check=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bdb206f0-bc57-479f-81b8-b833be66165b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train.jsonl  val.jsonl\n"
     ]
    }
   ],
   "source": [
    "!ls {OUTPUT_DIR}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "febe81b4-5add-45f6-8cd1-0a7d71f3175a",
   "metadata": {},
   "source": [
    "### Start vLLM Servers: Policy Model and Content Safety\n",
    "\n",
    "Download the `nvidia/llama-3.1-nemoguard-8b-content-safety` model from Hugging Face."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2a646d0f-031c-4337-b8ac-91200b6aa99c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching 4 files: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:12<00:00,  3.20s/it]\n",
      "Loading checkpoint shards: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00, 169.85it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('./workspace/training/model//llama-3.1-nemoguard-8b-content-safety/tokenizer_config.json',\n",
       " './workspace/training/model//llama-3.1-nemoguard-8b-content-safety/special_tokens_map.json',\n",
       " './workspace/training/model//llama-3.1-nemoguard-8b-content-safety/tokenizer.json')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from peft import PeftModel\n",
    "\n",
    "# Load base model\n",
    "from peft import PeftModel\n",
    "from transformers import AutoModelForCausalLM\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"meta-llama/Llama-3.1-8B-Instruct\")\n",
    "base_model = AutoModelForCausalLM.from_pretrained(\"meta-llama/Meta-Llama-3.1-8B-Instruct\", torch_dtype=torch.bfloat16)\n",
    "model = PeftModel.from_pretrained(base_model, \"nvidia/llama-3.1-nemoguard-8b-content-safety\")\n",
    "merged_model = model.merge_and_unload()\n",
    "\n",
    "# Save merged model\n",
    "merged_model.save_pretrained(SAFETY_MODEL_PATH, torch_dtype=torch.bfloat16)\n",
    "tokenizer.save_pretrained(SAFETY_MODEL_PATH)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "badfae55-e3e8-41cd-89c5-8924c1760a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The following block does not work for me :( (Yoshi)\n",
    "\n",
    "# # 4. Start vLLM servers\n",
    "# os.environ.update({\n",
    "#     'VLLM_ENGINE_ITERATION_TIMEOUT_S': '36000',\n",
    "#     'VLLM_ALLOW_LONG_MAX_MODEL_LEN': '1',\n",
    "#     'VLLM_HOST': '0.0.0.0',\n",
    "#     'VLLM_TENSOR_PARALLEL_SIZE': '4',\n",
    "#     'POLICY_MODEL_GPUS': '0,1,2,3',\n",
    "#     'SAFETY_MODEL_GPUS': '4,5,6,7',\n",
    "#     'TMPDIR': '/tmp' \n",
    "# })\n",
    "\n",
    "# print(\"Starting policy model server...\")\n",
    "# policy_server = subprocess.Popen([\n",
    "#     'python3', '-m', 'vllm.entrypoints.openai.api_server',\n",
    "#     '--model', MODEL_NAME_OR_PATH,\n",
    "#     '--trust-remote-code',\n",
    "#     '--seed', '1',\n",
    "#     '--host', os.environ['VLLM_HOST'],\n",
    "#     '--port', '5000',\n",
    "#     '--served-model-name', 'test-model',\n",
    "#     '--enable-reasoning', \n",
    "#     '--reasoning-parser', 'qwen3',\n",
    "#     '--tensor-parallel-size', os.environ['VLLM_TENSOR_PARALLEL_SIZE'],\n",
    "#     '--download-dir', os.environ['HF_HOME']\n",
    "# ], env={**os.environ, 'CUDA_VISIBLE_DEVICES': os.environ['POLICY_MODEL_GPUS']},\n",
    "#    stdout=open(f\"{LOG_DIR}/vllm-server-model.log\", 'w'),\n",
    "#    stderr=subprocess.STDOUT)\n",
    "\n",
    "# print(\"Starting safety model server...\")\n",
    "# safety_server = subprocess.Popen([\n",
    "#     'python3', '-m', 'vllm.entrypoints.openai.api_server',\n",
    "#     '--model', SAFETY_MODEL_PATH,\n",
    "#     '--trust-remote-code',\n",
    "#     '--seed', '1',\n",
    "#     '--host', os.environ['VLLM_HOST'],\n",
    "#     '--port', '6000',\n",
    "#     '--served-model-name', 'safety-model',\n",
    "#     '--tensor-parallel-size', os.environ['VLLM_TENSOR_PARALLEL_SIZE'],\n",
    "#     '--download-dir', os.environ['HF_HOME']\n",
    "# ], env={**os.environ, 'CUDA_VISIBLE_DEVICES': os.environ['SAFETY_MODEL_GPUS']},\n",
    "#    stdout=open(f\"{LOG_DIR}/vllm-server-safety.log\", 'w'),\n",
    "#    stderr=subprocess.STDOUT)\n",
    "\n",
    "# Cleanup vLLM servers\n",
    "# subprocess.run(['pkill', '-f', 'vllm.entrypoints.openai.api_server'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "01e54dd4-01bd-4290-953e-17caceb87533",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args=['pkill', '-f', 'vllm.entrypoints.openai.api_server'], returncode=1)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cleanup vLLM servers\n",
    "# subprocess.run(['pkill', '-f', 'vllm.entrypoints.openai.api_server'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a50387ea-22c6-4b5b-83fa-a564d1567169",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args=['pkill', '-f', 'generate_on_policy_data.py'], returncode=1)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Kill on-policy\n",
    "#subprocess.run(['pkill', '-f', 'generate_on_policy_data.py'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33541a90",
   "metadata": {},
   "source": [
    "### Generating On-Policy Data\n",
    "\n",
    "Using the combined dataset, the base model, and the content safety model, generate the on-policy data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e9f63bfd-c74f-4674-a1df-324b381cbbca",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating on-policy data...\n",
      "Data is Ready\n"
     ]
    }
   ],
   "source": [
    "CONCURRENCY = 16\n",
    "MAX_ATTEMPTS = 3\n",
    "BATCH_SIZE = 96\n",
    "\n",
    "MAX_TOKENS = 512\n",
    "TEMPERATURE = 0.7\n",
    "TOP_P = 0.9\n",
    "\n",
    "print(\"Generating on-policy data...\")\n",
    "for dataset_type in ['train', 'val']:\n",
    "    input_dataset = f\"{OUTPUT_DIR}/{dataset_type}.jsonl\"\n",
    "    output_file = f\"{OUTPUT_DIR}/{dataset_type}_on_policy_data.jsonl\"\n",
    "    DATASET_TYPE = dataset_type\n",
    "    subprocess.run([\n",
    "        'python3', 'generate_on_policy_data.py',\n",
    "        '--model_name', MODEL_NAME_OR_PATH,\n",
    "        '--safety_model', SAFETY_MODEL_NAME,\n",
    "        '--huggingface_token', os.environ['HF_TOKEN'],\n",
    "        '--vllm_host', os.environ['VLLM_HOST'],\n",
    "        '--vllm_model_port', '5000',\n",
    "        '--vllm_safety_port', '6000',\n",
    "        '--concurrency', str(CONCURRENCY),\n",
    "        '--input_dataset', input_dataset,\n",
    "        '--output', output_file,\n",
    "        '--batch_size', str(BATCH_SIZE),\n",
    "        '--max_tokens', str(MAX_TOKENS),\n",
    "        '--temperature', str(TEMPERATURE),\n",
    "        '--top_p', str(TOP_P)\n",
    "    ], stdout=open(f\"{LOG_DIR}/{DATASET_TYPE}_on-policy.log\", 'w'),\n",
    "                   stderr=subprocess.STDOUT)\n",
    "\n",
    "print(\"Data is Ready\")\n",
    "    \n",
    "# Cleanup vLLM servers\n",
    "# subprocess.run(['pkill', '-f', 'vllm.entrypoints.openai.api_server'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "38e6b5e7-4fce-4563-8896-322e77f125cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args=['pkill', '-f', 'vllm.entrypoints.openai.api_server'], returncode=0)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cleanup vLLM servers\n",
    "subprocess.run(['pkill', '-f', 'vllm.entrypoints.openai.api_server'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8b87c2a9-1164-4e27-bc26-277462e34743",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# !ps -aux | grep python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ce784cb",
   "metadata": {},
   "source": [
    "### Fine-Tune the Model\n",
    "\n",
    "Use NeMo-RL to post-train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7e42fbf0-bd6d-480b-b56b-a35ef4a04bb8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running SFT...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args=['uv', 'run', 'python', 'examples/run_sft.py', '--config', '/lustre/fsw/llmservice_nemo_mlops/users/ysuhara/work/gitlab/NeMo-Safety/notebooks/deepseek_sft.yaml'], returncode=0)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.chdir(\"/lustre/fsw/llmservice_nemo_mlops/users/ysuhara/work/gitlab/NeMo-Safety/notebooks\")\n",
    "#!ln -s `readlink -f workspace` /workspace/NeMo-RL/\n",
    "\n",
    "MODEL_DIR = os.path.abspath(f\"{BASE_DIR}/results/DeepSeek-R1-Distill-Llama-8B/\")\n",
    "!mkdir -p {MODEL_DIR}\n",
    "config_filepath = os.path.abspath(\"deepseek_sft.yaml\")\n",
    "\n",
    "print(\"Running SFT...\")\n",
    "# Set up model directory environment variable\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0,1,2,3,4,5,6,7\"\n",
    "os.chdir(\"/workspace/NeMo-RL\")\n",
    "subprocess.run(['uv', 'run', 'python', 'examples/run_sft.py', \n",
    "                '--config', config_filepath\n",
    "               ], \n",
    "               env={**os.environ, 'TMPDIR': os.environ['RAY_TMPDIR']},\n",
    "               stdout=open(f\"{MODEL_DIR}/sft.stdout\", 'w'),\n",
    "               stderr=open(f\"{MODEL_DIR}/sft.stderr\", 'w'),               \n",
    "               check=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08d3f900",
   "metadata": {},
   "source": [
    "Convert the checkpoints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a57c51b6-5765-49ec-bb1d-69d58527c234",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting checkpoint...\n",
      "Saved HF checkpoint to: /lustre/fsw/llmservice_nemo_mlops/users/ysuhara/work/gitlab/NeMo-Safety/notebooks/workspace/training/results/DeepSeek-R1-Distill-Llama-8B/DeepSeek-R1-Distill-Llama-8B-Safety-Trained\n",
      "Conversion successful!\n",
      "The HuggingFace model is now available at: /lustre/fsw/llmservice_nemo_mlops/users/ysuhara/work/gitlab/NeMo-Safety/notebooks/workspace/training/results/DeepSeek-R1-Distill-Llama-8B/DeepSeek-R1-Distill-Llama-8B-Safety-Trained\n"
     ]
    }
   ],
   "source": [
    "CHECKPOINT_DIR = f\"{BASE_DIR}/results/DeepSeek-R1-Distill-Llama-8B/step_25\"\n",
    "DCP_CKPT_PATH = f\"{CHECKPOINT_DIR}/policy/weights/\"\n",
    "CONFIG_PATH = f\"{CHECKPOINT_DIR}/config.yaml\"\n",
    "HF_CKPT_PATH = f\"{MODEL_DIR}/DeepSeek-R1-Distill-Llama-8B-Safety-Trained\"\n",
    "\n",
    "print(\"Converting checkpoint...\")\n",
    "#os.chdir(f\"{BASE_DIR}/NeMo-RL\")\n",
    "os.chdir(f\"/workspace/NeMo-RL\")\n",
    "subprocess.run([\n",
    "    'uv', 'run', 'examples/convert_dcp_to_hf.py',\n",
    "    '--config', CONFIG_PATH,\n",
    "    '--dcp-ckpt-path', DCP_CKPT_PATH,\n",
    "    '--hf-ckpt-path', HF_CKPT_PATH\n",
    "], check=True)\n",
    "\n",
    "# Verify conversion\n",
    "if Path(f\"{HF_CKPT_PATH}/pytorch_model.bin\").exists() and Path(f\"{HF_CKPT_PATH}/config.json\").exists():\n",
    "    print(\"Conversion successful!\")\n",
    "    print(f\"The HuggingFace model is now available at: {HF_CKPT_PATH}\")\n",
    "else:\n",
    "    print(\"Conversion may have failed. Please check the output.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d82a515-2a5a-4037-8096-d3aa6b2e1a8e",
   "metadata": {},
   "source": [
    "### Next Steps\n",
    "\n",
    "You used post-training to improve the safety of the model, retained the accuracy of the original model, and saved the checkpoints.\n",
    "\n",
    "The next step is to [evaluate the safety and accuracy of the model](./Step3_Post_Training_Eval.ipynb)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
