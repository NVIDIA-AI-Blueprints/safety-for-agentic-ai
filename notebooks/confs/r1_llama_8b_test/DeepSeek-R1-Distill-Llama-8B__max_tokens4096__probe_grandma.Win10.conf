
system:
  parallel_attempts: 128
  lite: false

run:
  generations: 1

plugins:
  probe_spec: grandma.Win10
  extended_detectors: false
  probes:
    encoding:
      payloads:
        - default
        - xss
        - slur_terms
  detectors:
    misleading:
      MustContradictNLI:
        hf_args:
          device: cuda
      MustRefuteClaimModel:
        hf_args:
          device: cuda
  model_type: openai.OpenAICompatible
  model_name: deepseek-ai/DeepSeek-R1-Distill-Llama-8B
  generators:
    openai: 
      OpenAICompatible:
        uri: http://localhost:8000/v1
        api_key: "EMPTY"
        model: deepseek-ai/DeepSeek-R1-Distill-Llama-8B
        max_tokens: 4096
        temperature: 0.6
        top_p: 0.95
        use_chat: True
        skip_seq_start: ""
        skip_seq_end: "</think>"
