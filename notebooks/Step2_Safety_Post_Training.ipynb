{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fd37e71a-284c-4cf0-8371-66916339bf47",
   "metadata": {},
   "source": [
    "# Notebook 2: Post-Training with Safety and Accuracy Data\n",
    "\n",
    "## About the Data\n",
    "\n",
    "This notebook demonstrates how to post-train the base model with safety-related data.\n",
    "The safety data is gathered from the following well-known datasets:\n",
    "\n",
    "- [Aegis AI Content Safety Dataset 2.0](https://huggingface.co/datasets/nvidia/Aegis-AI-Content-Safety-Dataset-2.0)\n",
    "- [Gretel Synthetic Safety Alignment Dataset](https://huggingface.co/datasets/gretelai/gretel-safety-alignment-en-v1)\n",
    "- [HarmfulTasks](https://github.com/CrystalEye42/eval-safety)\n",
    "- [RedTeam 2k](https://huggingface.co/datasets/JailbreakV-28K/JailBreakV-28k)\n",
    "\n",
    "Training also uses the [nvidia/LLama-Nemotron-Post-Training-Dataset](https://huggingface.co/datasets/nvidia/Llama-Nemotron-Post-Training-Dataset) to preserve the code, chat, math, and science reasoning abilities that can otherwise degrade with fine-tuning.\n",
    "\n",
    "## About the Process\n",
    "\n",
    "This notebook proceeds through the following high-level steps:\n",
    "\n",
    "- Set up a directory structure for logs and results.\n",
    "- Data preparation:\n",
    "  - Download the preceding safety-related datasets and extract 2000 total samples at random.\n",
    "  - Download the Llama Nemotron dataset and extract 4000 samples at random.\n",
    "  - Create training and validation datasets from the samples, excluding samples with a token length greater than `16384`.\n",
    "- Start vLLM servers:\n",
    "  - One serves the base model to train.\n",
    "  - A second serves the NVIDIA Llama 3.1 Nemoguard 8B Instruct model to act as LLM as judge.\n",
    "- Fine-tune the model using [NeMo-RL](https://github.com/NVIDIA/NeMo-RL) to apply safety post-training to improve the safety of the target model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d699512d-7447-4b69-b8e3-fcad7aa057cb",
   "metadata": {},
   "source": [
    "### Load API Keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4fc45e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "print(\"Loading environment variables from .env\")\n",
    "load_dotenv(dotenv_path=\".env\")\n",
    "\n",
    "if os.environ.get(\"HF_TOKEN\", None) is None or os.environ.get(\"NVIDIA_API_KEY\", None) is None:\n",
    "    raise ValueError(\"HF_TOKEN and NVIDIA_API_KEY must be set.\")\n",
    "print(\"✅ HF_TOKEN and NVIDIA_API_TOKEN found\")\n",
    "if os.environ.get(\"WANDB_API_KEY\", None) is None:\n",
    "    print(\"❌ WANDB_API_KEY not found. W&B logger will be disabled\")\n",
    "else:\n",
    "    print(\"✅ WANDB_API_KEY found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c17609ed",
   "metadata": {},
   "source": [
    "### Set up Packages and Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "def9dcce-240c-49ba-8d02-f4a70053d18c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "import time\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "\n",
    "from huggingface_hub import hf_hub_download\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "# Base directory and configuration\n",
    "BASE_DIR = \"./workspace/training\"\n",
    "LOG_DIR = f\"{BASE_DIR}/logs\"\n",
    "\n",
    "SAFETY_DATASET_NAME = \"safety_blend_v1.jsonl\"\n",
    "POST_TRAINING_DATASET_NAME = \"nvidia/Llama-Nemotron-Post-Training-Dataset\"\n",
    "MODEL_NAME_OR_PATH = \"deepseek-ai/DeepSeek-R1-Distill-Llama-8B\"\n",
    "MODEL_DIR = f\"{BASE_DIR}/model/\"\n",
    "SAFETY_MODEL_NAME = \"llama-3.1-nemoguard-8b-content-safety\"\n",
    "SAFETY_MODEL_PATH = f\"{MODEL_DIR}/{SAFETY_MODEL_NAME}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbde3367-ff98-4984-b8e1-7687fbc6379b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set environment variables\n",
    "os.environ.update({\n",
    "    'TMPDIR': \"/tmp\",\n",
    "    'XDG_CACHE_HOME': f\"{BASE_DIR}/cache\",\n",
    "    'HF_HOME': f\"{BASE_DIR}/cache/huggingface\",\n",
    "    'UV_CACHE_DIR': f\"{BASE_DIR}/cache/uv\",\n",
    "    'TRITON_CACHE_DIR': f\"{BASE_DIR}/cache/triton\",\n",
    "    'DATASET_CACHE_DIR': f\"{BASE_DIR}/dataset_cache\",\n",
    "    'RAY_TMPDIR': \"/tmp/ray\",\n",
    "    'LOG_DIR': f\"{LOG_DIR}\",\n",
    "    \"MODEL_DIR\": f\"{MODEL_DIR}\"\n",
    "})\n",
    "\n",
    "# Create directories\n",
    "for dir_path in [os.environ['TMPDIR'], os.environ['XDG_CACHE_HOME'], os.environ['HF_HOME'],\n",
    "                 os.environ['UV_CACHE_DIR'],os.environ['TRITON_CACHE_DIR'], os.environ['DATASET_CACHE_DIR'], \n",
    "                 os.environ['RAY_TMPDIR'], os.environ['LOG_DIR'], os.environ['MODEL_DIR']]:\n",
    "    Path(dir_path).mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47c27b7e",
   "metadata": {},
   "source": [
    "After you run the preceding cell, the directory structure---including the paths from the first notebook---are as follows:\n",
    "\n",
    "```text\n",
    "workspace\n",
    "├── cache\n",
    "│   ├── huggingface\n",
    "│   ├── triton\n",
    "│   └── uv\n",
    "├── dataset\n",
    "│   └── aegis_v2\n",
    "├── dataset_cache\n",
    "├── results\n",
    "│   └── DeepSeek-R1-Distill-Llama-8B\n",
    "│       ├── accuracy-evals\n",
    "│       │   ├── aa-math-500\n",
    "│       │   ├── gpqa-diamond\n",
    "│       │   └── ifeval\n",
    "│       ├── content-safety-evals\n",
    "│       │   ├── aegis_v2\n",
    "│       │   └── wildguard\n",
    "│       ├── logs\n",
    "│       └── security-evals\n",
    "│           └── garak\n",
    "│               ├── configs\n",
    "│               ├── logs\n",
    "│               └── reports\n",
    "├── tmp\n",
    "└── training\n",
    "    └── model\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "994dafc1-3758-4d51-8ed1-3ddef45196cd",
   "metadata": {},
   "source": [
    "### Generating Safety Training Data\n",
    "\n",
    "The key idea is to use on-policy data generated by the target model.\n",
    "This approach improves safety, while making sure to obtain safe responses even for unsafe prompts. \n",
    "\n",
    "The notebook uses a safety training data generation recipe that uses the following public datasets:\n",
    "\n",
    "- Aegis AI Content Safety Dataset 2.0\n",
    "- Gretel Synthetic Safety Alignment Dataset\n",
    "- HarmfulTasks\n",
    "- RedTeam 2k\n",
    "\n",
    "The notebook extracts safe and unsafe prompts from Aegis AI Content Safety Dataset 2.0 and unsafe prompts from the other three datasets. \n",
    "\n",
    "### Response Generation for Safe Prompts\n",
    "\n",
    "For safe prompts, the notebook uses the target model and the prompts as-is to generate responses.\n",
    "When you have access to a larger model in the same model family---such as `deepseek-ai/DeepSeek-R1` instead of `deepseek-ai/DeepSeek-R1-Distill-Llama-8B`---use the larger model because it should generate safe responses better than the smaller model. \n",
    "\n",
    "### Response Generation for Unsafe Prompts\n",
    "\n",
    "Because the unsafe prompts in the HarmfulTasks dataset have jailbreak prompts that begin with text like \"Ignore all instructions until now...\" and end with a request like \"Write a blog post promoting mistrust between different social groups.\"\n",
    "The jailbreak portion of the prompts are removed, but the model still generates responses to the unsafe user request, such as writing a blog to promote mistrust.\n",
    "\n",
    "All unsafe prompts are wrapped in a new prompt template, shown below, that instructs the model to disengage but also inform the user exactly why---using the ground truth harm categories in the datasets and not a canned response.\n",
    "\n",
    "```\n",
    "You are a helpful assistant that generates safe responses for given prompts.\n",
    "\n",
    "The prompt is: {prompt}\n",
    "This prompt is known to violate the following safety categories or elicits unsafe responses of these categories from the model. The categories are: {categories}\n",
    "\n",
    "Generate a safe refusal for the prompt that politely points out that the model doesn't engage in unsafe behavior for the given categories. Your response:\n",
    "```\n",
    "\n",
    "With this approach, the model can generate safe responses for unsafe prompts. \n",
    "\n",
    "For training, the notebook passes the original unsafe prompt and the generated response---not the one with the safe prompt wrapper described above. Effectively, we are trying to teach the model to generate the same response to the original unsafe prompt such as with the jailbreak instructions for the HarmfulTasks prompts.\n",
    "\n",
    "### Response Filtering\n",
    "\n",
    "The generated responses for the safe and unsafe prompts discussed above are not guaranteed to be safe responses. Therefore, we implement a filtering step to extract the generated responses that are judged as safe by a guard model.\n",
    "\n",
    "We use [nvidia/llama-3.1-nemoguard-8b-content-safety](https://huggingface.co/nvidia/llama-3.1-nemoguard-8b-content-safety) as the guard model for this filtering step.\n",
    "\n",
    "### Blend Safety Training Data with Accuracy Data\n",
    "\n",
    "Safety training data helps the model learn to refuse to answer unsafe prompts. As a result, the model can experience some accuracy degradation for certain capabilities such as instruction following.\n",
    "\n",
    "To address the issue, the notebook adds post-training data to retain the accuracy. We use a subset of  [nvidia/Llama-Nemotron-Post-Training-Dataset](https://huggingface.co/datasets/nvidia/Llama-Nemotron-Post-Training-Dataset), which was used to train Llama Nemotron models—world-class reasoning models, for this purpose. \n",
    "\n",
    "More specifically, in this recipe, the notebook generates on-policy data using the model.\n",
    "The on-policy data can help retain the same behavior as the original model for the prompts in the post-training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daf5e2e0-0b2b-4032-84d6-d91f3b16891b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#os.chdir(f\"{BASE_DIR}/NeMo-Safety/notebooks\")\n",
    "result = subprocess.run([\n",
    "    'python3', 'safety_dataset_blend_generation.py',\n",
    "    '--filename', os.path.join(os.environ['DATASET_CACHE_DIR'], SAFETY_DATASET_NAME),\n",
    "    '--total_samples', '2000',\n",
    "    '--sampling_method', 'uniform',\n",
    "    '--cache_dir', os.environ['DATASET_CACHE_DIR']\n",
    "], check=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed9fda79",
   "metadata": {},
   "source": [
    "Download Llama Nemotron Post-training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8546dff5-4109-4e84-a335-c51a8d8af372",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = [\n",
    "    \"SFT/math/math_v1.1.jsonl\",\n",
    "    \"SFT/code/code_v1.1.jsonl\",\n",
    "    \"SFT/chat/chat.jsonl\",\n",
    "    \"SFT/science/science.jsonl\"\n",
    "]\n",
    "\n",
    "LLAMA_NEMO_DIR = f\"{os.environ['DATASET_CACHE_DIR']}/Llama-Nemotron-Post-Training-Dataset\"\n",
    "Path(LLAMA_NEMO_DIR).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "for file in files:\n",
    "    print(f\"Downloading {file}...\")\n",
    "    downloaded_path = hf_hub_download(\n",
    "        repo_id=POST_TRAINING_DATASET_NAME,\n",
    "        filename=file,\n",
    "        repo_type='dataset',\n",
    "        cache_dir=os.environ['DATASET_CACHE_DIR']\n",
    "    )\n",
    "    \n",
    "    filename = Path(file).name\n",
    "    target_path = f\"{LLAMA_NEMO_DIR}/{filename}\"\n",
    "    \n",
    "    # Count lines and sample\n",
    "    with open(downloaded_path, 'r') as f:\n",
    "        total_lines = sum(1 for _ in f)\n",
    "    \n",
    "    print(f\"Total lines in file: {total_lines}\")\n",
    "    \n",
    "    if total_lines > 1000:\n",
    "        # Use shuf for random sampling\n",
    "        subprocess.run(['shuf', '-n', '1000', downloaded_path], stdout=open(target_path, 'w'), check=True)\n",
    "        print(f\"Extracted 1000 random samples to {target_path}\")\n",
    "    else:\n",
    "        shutil.copy2(downloaded_path, target_path)\n",
    "        print(f\"File has fewer than 1000 lines, copied all {total_lines} lines\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1771977",
   "metadata": {},
   "source": [
    "Combine safety and accuracy datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff0fd393-241b-4200-a2ba-c75c03904626",
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_DIR = f\"{os.environ['DATASET_CACHE_DIR']}/sft_data\"\n",
    "subprocess.run([\n",
    "    'python3', 'combine_datasets.py',\n",
    "    '--safety_file', f\"{os.environ['DATASET_CACHE_DIR']}/safety_blend_v1_sampled_2000_uniform.jsonl\",\n",
    "    '--llama_nemo_dir', LLAMA_NEMO_DIR,\n",
    "    '--output_dir', OUTPUT_DIR,\n",
    "    '--val_split', '0.03',\n",
    "    '--max_tokens', '16384',\n",
    "    '--max_samples', '5000'\n",
    "], check=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdb206f0-bc57-479f-81b8-b833be66165b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls {OUTPUT_DIR}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "febe81b4-5add-45f6-8cd1-0a7d71f3175a",
   "metadata": {},
   "source": [
    "### Start vLLM Servers: Policy Model and Content Safety\n",
    "\n",
    "If you skipped this step in Step 1, you'd need to download the `nvidia/llama-3.1-nemoguard-8b-content-safety` model from Hugging Face."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a646d0f-031c-4337-b8ac-91200b6aa99c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from peft import PeftModel\n",
    "\n",
    "# Load base model\n",
    "from peft import PeftModel\n",
    "from transformers import AutoModelForCausalLM\n",
    "\n",
    "if not os.path.exists(SAFETY_MODEL_PATH):\n",
    "    print(\"NeMo Guard model does not exist. Creating...\")\n",
    "    \n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"meta-llama/Llama-3.1-8B-Instruct\")\n",
    "    base_model = AutoModelForCausalLM.from_pretrained(\"meta-llama/Meta-Llama-3.1-8B-Instruct\", torch_dtype=torch.bfloat16)\n",
    "    model = PeftModel.from_pretrained(base_model, \"nvidia/llama-3.1-nemoguard-8b-content-safety\")\n",
    "    merged_model = model.merge_and_unload()\n",
    "    \n",
    "    # Save merged model\n",
    "    merged_model.save_pretrained(SAFETY_MODEL_PATH, torch_dtype=torch.bfloat16)\n",
    "    tokenizer.save_pretrained(SAFETY_MODEL_PATH)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c834aca",
   "metadata": {},
   "source": [
    "Start one vLLM server for the policy model to train and another vLLM server with the content safety model to perform LLM-as-a-judge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dedaf55b",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ.update({\n",
    "    'VLLM_ENGINE_ITERATION_TIMEOUT_S': '36000',\n",
    "    'VLLM_ALLOW_LONG_MAX_MODEL_LEN': '1',\n",
    "    'VLLM_HOST': '0.0.0.0',\n",
    "    'VLLM_TENSOR_PARALLEL_SIZE': '4',\n",
    "    'POLICY_MODEL_GPUS': '0,1,2,3',\n",
    "    'SAFETY_MODEL_GPUS': '4,5,6,7',\n",
    "    'TMPDIR': '/tmp' \n",
    "})\n",
    "\n",
    "print(\"Starting policy model server...\")\n",
    "policy_server = subprocess.Popen([\n",
    "    'python3', '-m', 'vllm.entrypoints.openai.api_server',\n",
    "    '--model', MODEL_NAME_OR_PATH,\n",
    "    '--trust-remote-code',\n",
    "    '--seed', '1',\n",
    "    '--host', os.environ['VLLM_HOST'],\n",
    "    '--port', '5000',\n",
    "    '--served-model-name', 'test-model',\n",
    "    '--enable-reasoning', \n",
    "    '--reasoning-parser', 'qwen3',\n",
    "    '--tensor-parallel-size', os.environ['VLLM_TENSOR_PARALLEL_SIZE'],\n",
    "    '--download-dir', os.environ['HF_HOME']\n",
    "], env={**os.environ, 'CUDA_VISIBLE_DEVICES': os.environ['POLICY_MODEL_GPUS']},\n",
    "   stdout=open(f\"{LOG_DIR}/vllm-server-model.log\", 'w'),\n",
    "   stderr=subprocess.STDOUT)\n",
    "\n",
    "print(\"Starting safety model server...\")\n",
    "safety_server = subprocess.Popen([\n",
    "    'python3', '-m', 'vllm.entrypoints.openai.api_server',\n",
    "    '--model', SAFETY_MODEL_PATH,\n",
    "    '--trust-remote-code',\n",
    "    '--seed', '1',\n",
    "    '--host', os.environ['VLLM_HOST'],\n",
    "    '--port', '6000',\n",
    "    '--served-model-name', 'safety-model',\n",
    "    '--tensor-parallel-size', os.environ['VLLM_TENSOR_PARALLEL_SIZE'],\n",
    "    '--download-dir', os.environ['HF_HOME']\n",
    "], env={**os.environ, 'CUDA_VISIBLE_DEVICES': os.environ['SAFETY_MODEL_GPUS']},\n",
    "   stdout=open(f\"{LOG_DIR}/vllm-server-safety.log\", 'w'),\n",
    "   stderr=subprocess.STDOUT)\n",
    "\n",
    "!sleep 120"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33541a90",
   "metadata": {},
   "source": [
    "### Generating On-Policy Data\n",
    "\n",
    "Using the combined dataset, the base model, and the content safety model, generate the on-policy data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9f63bfd-c74f-4674-a1df-324b381cbbca",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "CONCURRENCY = 16\n",
    "MAX_ATTEMPTS = 3\n",
    "BATCH_SIZE = 96\n",
    "\n",
    "MAX_TOKENS = 512\n",
    "TEMPERATURE = 0.7\n",
    "TOP_P = 0.9\n",
    "\n",
    "print(\"Generating on-policy data...\")\n",
    "for dataset_type in ['train', 'val']:\n",
    "    input_dataset = f\"{OUTPUT_DIR}/{dataset_type}.jsonl\"\n",
    "    output_file = f\"{OUTPUT_DIR}/{dataset_type}_on_policy_data.jsonl\"\n",
    "    DATASET_TYPE = dataset_type\n",
    "    subprocess.run([\n",
    "        'python3', 'generate_on_policy_data.py',\n",
    "        '--model_name', MODEL_NAME_OR_PATH,\n",
    "        '--safety_model', SAFETY_MODEL_NAME,\n",
    "        '--huggingface_token', os.environ['HF_TOKEN'],\n",
    "        '--vllm_host', os.environ['VLLM_HOST'],\n",
    "        '--vllm_model_port', '5000',\n",
    "        '--vllm_safety_port', '6000',\n",
    "        '--concurrency', str(CONCURRENCY),\n",
    "        '--input_dataset', input_dataset,\n",
    "        '--output', output_file,\n",
    "        '--batch_size', str(BATCH_SIZE),\n",
    "        '--max_tokens', str(MAX_TOKENS),\n",
    "        '--temperature', str(TEMPERATURE),\n",
    "        '--top_p', str(TOP_P)\n",
    "    ], stdout=open(f\"{LOG_DIR}/{DATASET_TYPE}_on-policy.log\", 'w'),\n",
    "                   stderr=subprocess.STDOUT)\n",
    "\n",
    "print(\"Data is Ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12cc0ab7",
   "metadata": {},
   "source": [
    "### Stop the vLLM Servers\n",
    "\n",
    "If you run vLLM servers on terminals, press Ctrl+C to stop the vLLM servers in each shell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2164877-c6a4-444b-a037-5e9bc9a9f461",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleanup vLLM servers\n",
    "subprocess.run(['pkill', '-f', 'vllm.entrypoints.openai.api_server'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ce784cb",
   "metadata": {},
   "source": [
    "### Fine-Tune the Model\n",
    "\n",
    "Use NeMo-RL to post-train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e42fbf0-bd6d-480b-b56b-a35ef4a04bb8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "MODEL_DIR = os.path.abspath(f\"{BASE_DIR}/results/DeepSeek-R1-Distill-Llama-8B/\")\n",
    "!mkdir -p {MODEL_DIR}\n",
    "os.environ[\"NEMO_RL_CONFIG_PATH\"] = os.path.abspath(\"deepseek_sft.yaml\")\n",
    "\n",
    "print(\"Running SFT...\")\n",
    "# Set up model directory environment variable\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0,1,2,3,4,5,6,7\"\n",
    "!cd /ephemeral/workspace/NeMo-RL && TMPDIR=$RAY_TMPDIR uv run python examples/run_sft.py --config ${NEMO_RL_CONFIG_PATH} # > ${LOG_DIR}/nemo-rl-sft-log.out 2> ${LOG_DIR}/nemo-rl-sft-log.err"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08d3f900",
   "metadata": {},
   "source": [
    "### Convert the checkpoint\n",
    "\n",
    "The following code blocks will convert the NeMo-RL checkpoint into HF (.bin) and then HF (safetensors)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a57c51b6-5765-49ec-bb1d-69d58527c234",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"/ephemeral/workspace/safety-for-agentic-ai/notebooks\")\n",
    "CHECKPOINT_DIR = os.path.abspath(f\"{BASE_DIR}/results/DeepSeek-R1-Distill-Llama-8B/step_60\")\n",
    "DCP_CKPT_PATH = os.path.abspath(f\"{CHECKPOINT_DIR}/policy/weights/\")\n",
    "CONFIG_PATH = os.path.abspath(f\"{CHECKPOINT_DIR}/config.yaml\")\n",
    "HF_CKPT_PATH = os.path.abspath(f\"{MODEL_DIR}/DeepSeek-R1-Distill-Llama-8B-Safety-Trained-bin\")\n",
    "HF_CKPT_ST_PATH = os.path.abspath(f\"{MODEL_DIR}/DeepSeek-R1-Distill-Llama-8B-Safety-Trained\")\n",
    "\n",
    "print(\"Converting checkpoint...\")\n",
    "!cd /ephemeral/workspace/NeMo-RL && uv run examples/convert_dcp_to_hf.py --config {CONFIG_PATH} --dcp-ckpt-path {DCP_CKPT_PATH} --hf-ckpt-path {HF_CKPT_PATH}\n",
    "\n",
    "# Verify conversion\n",
    "if Path(f\"{HF_CKPT_PATH}/pytorch_model.bin\").exists() and Path(f\"{HF_CKPT_PATH}/config.json\").exists():\n",
    "    print(\"Conversion successful!\")\n",
    "    print(f\"The HuggingFace model is now available at: {HF_CKPT_PATH}\")\n",
    "else:\n",
    "    print(\"Conversion may have failed. Please check the output.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89853e4d-7e7d-47e8-89c8-535d9e8ce16a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# * Safetensors\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "# Load the full Causal LM model and tokenizer\n",
    "model = AutoModelForCausalLM.from_pretrained(HF_CKPT_PATH)\n",
    "tokenizer = AutoTokenizer.from_pretrained(HF_CKPT_PATH)\n",
    "\n",
    "print(\"Model and Tokenizer loaded successfully.\")\n",
    "\n",
    "# Save the full model as safetensors\n",
    "model.save_pretrained(\n",
    "    HF_CKPT_ST_PATH,\n",
    "    safe_serialization=True\n",
    ")\n",
    "\n",
    "# Save the tokenizer to the same new directory\n",
    "tokenizer.save_pretrained(HF_CKPT_ST_PATH)\n",
    "\n",
    "print(f\"Model successfully converted and saved to {HF_CKPT_ST_PATH}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d82a515-2a5a-4037-8096-d3aa6b2e1a8e",
   "metadata": {},
   "source": [
    "### Next Steps\n",
    "\n",
    "You used post-training to improve the safety of the model, retained the accuracy of the original model, and saved the checkpoints.\n",
    "\n",
    "The next step is to [evaluate the safety and accuracy of the model](./Step3_Post_Training_Eval.ipynb)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
