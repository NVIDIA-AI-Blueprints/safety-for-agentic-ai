{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aed4bbfc",
   "metadata": {},
   "source": [
    "# Step 1 Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d78ecde6-5a2f-4799-82b5-52396ecbbf79",
   "metadata": {},
   "outputs": [],
   "source": [
    "import concurrent.futures\n",
    "import json\n",
    "import os\n",
    "import subprocess\n",
    "import time\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "\n",
    "import openai\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5dace57a-3941-402e-bcc4-68cc5637d6fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. Run Baseline Evaluation - Run Evaluations in Background\n",
    "BASE_DIR = \"./workspace/\"\n",
    "LOG_DIR = f\"{BASE_DIR}/logs/\"\n",
    "DATASET_DIR = f\"{BASE_DIR}/dataset/\"\n",
    "MODEL_NAME_OR_PATH = \"deepseek-ai/DeepSeek-R1-Distill-Llama-8B\"\n",
    "MODEL_TAG_NAME = MODEL_NAME_OR_PATH.split(\"/\")[-1]\n",
    "\n",
    "# * Dataset\n",
    "AEGIS_V2_TEST_DIR = f\"{DATASET_DIR}/aegis_v2\"\n",
    "\n",
    "# * Content Safety benchmark\n",
    "CONTENT_SAFETY_RESULTS_DIR = f\"{BASE_DIR}/results/{MODEL_TAG_NAME}/content-safety-evals\"\n",
    "AEGIS_V2_RESULTS_DIR = f\"{CONTENT_SAFETY_RESULTS_DIR}/aegis_v2\"\n",
    "WILDGUARD_RESULTS_DIR = f\"{CONTENT_SAFETY_RESULTS_DIR}/wildguard\"\n",
    "\n",
    "# * Security benchmark\n",
    "SECURITY_RESULTS_DIR = f\"{BASE_DIR}/results/{MODEL_TAG_NAME}/security-evals\"\n",
    "GARAK_RESULTS_DIR = f\"{SECURITY_RESULTS_DIR}/garak\"\n",
    "\n",
    "# * Accuracy benchmark\n",
    "ACCURACY_RESULTS_DIR = f\"{BASE_DIR}/results/{MODEL_TAG_NAME}/accuracy-evals\"\n",
    "GPQA_DIAMOND_RESULTS_DIR = f\"{ACCURACY_RESULTS_DIR}/gpqa-diamond\"\n",
    "AA_MATH_500_RESULTS_DIR = f\"{ACCURACY_RESULTS_DIR}/aa-math-500\"\n",
    "IFEVAL_RESULTS_DIR = f\"{ACCURACY_RESULTS_DIR}/ifeval\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1b819902",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create directories to store logs and results\n",
    "!mkdir -p {LOG_DIR}\n",
    "!mkdir -p {AEGIS_V2_TEST_DIR}\n",
    "!mkdir -p {AEGIS_V2_RESULTS_DIR}\n",
    "!mkdir -p {WILDGUARD_RESULTS_DIR}\n",
    "!mkdir -p {GARAK_RESULTS_DIR}\n",
    "!mkdir -p {GPQA_DIAMOND_RESULTS_DIR}\n",
    "!mkdir -p {AA_MATH_500_RESULTS_DIR}\n",
    "!mkdir -p {IFEVAL_RESULTS_DIR}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ecd2311-1b5e-4b0a-a597-f9ef166ae8ab",
   "metadata": {},
   "source": [
    "- Create NVIDIA API Key\n",
    "- Add Hugging Face token\n",
    "- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b1fc6a2c-b364-4651-8df0-8f263ee4af9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Credentials\n",
    "os.environ.update({\n",
    "    \"MY_API_KEY\":\"empty\",\n",
    "    \"JUDGE_API_KEY\": \"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\",\n",
    "    \"HF_TOKEN\": \"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\"\n",
    "})\n",
    "\n",
    "os.environ.update({\n",
    "    'BASE_DIR': f\"{BASE_DIR}\",\n",
    "    'TMPDIR': f\"{BASE_DIR}/tmp\",\n",
    "    'XDG_CACHE_HOME': f\"{BASE_DIR}/cache\",\n",
    "    'HF_HOME': f\"{BASE_DIR}/cache/huggingface\",\n",
    "    'UV_CACHE_DIR': f\"{BASE_DIR}/cache/uv\",\n",
    "    'TRITON_CACHE_DIR': f\"{BASE_DIR}/cache/triton\",\n",
    "    'DATASET_CACHE_DIR': f\"{BASE_DIR}/dataset_cache\",\n",
    "    'RAY_TMPDIR': \"/tmp/ray\",\n",
    "    'LOG_DIR': f\"{LOG_DIR}\"\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ddf3324-43f5-48a8-93f8-ee45cdc4220e",
   "metadata": {},
   "source": [
    "## Launch vLLM server\n",
    "\n",
    "Explain why\n",
    "\n",
    "```\n",
    "export MODEL_NAME_OR_PATH=\"deepseek-ai/DeepSeek-R1-Distill-Llama-8B\"\n",
    "export VLLM_TENSOR_PARALLEL_SIZE=8\n",
    "export HF_HOME=./workspace/cache/huggingface\n",
    "export LOG_DIR=./workspace/logs\n",
    "python3 -m vllm.entrypoints.openai.api_server \\\n",
    "  --model \"$MODEL_NAME_OR_PATH\" \\\n",
    "  --trust-remote-code \\\n",
    "  --seed 1 \\\n",
    "  --host \"$VLLM_HOST\" \\\n",
    "  --port 5000 \\\n",
    "  --served-model-name \"test-model\" \\\n",
    "  --enable-reasoning \\\n",
    "  --reasoning-parser qwen3 \\\n",
    "  --tensor-parallel-size \"$VLLM_TENSOR_PARALLEL_SIZE\" \\\n",
    "  --download-dir=\"$HF_HOME\"\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bca15ed7-8a04-4890-b4a6-1c350dea2ac0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting policy model server...\n"
     ]
    }
   ],
   "source": [
    "# VLLM Host \n",
    "os.environ.update({\n",
    "    'VLLM_ENGINE_ITERATION_TIMEOUT_S': '36000',\n",
    "    'VLLM_ALLOW_LONG_MAX_MODEL_LEN': '1',\n",
    "    'VLLM_HOST': '0.0.0.0',\n",
    "    'VLLM_TENSOR_PARALLEL_SIZE': '1',\n",
    "    'POLICY_MODEL_GPUS': '0,1,2,3',\n",
    "    'SAFETY_MODEL_GPUS': '4,5'\n",
    "})\n",
    "\n",
    "print(\"Starting policy model server...\")\n",
    "policy_server = subprocess.Popen([\n",
    "    'python3', '-m', 'vllm.entrypoints.openai.api_server',\n",
    "    '--model', MODEL_NAME_OR_PATH,\n",
    "    '--trust-remote-code',\n",
    "    '--seed', '1',\n",
    "    '--host', os.environ['VLLM_HOST'],\n",
    "    '--port', '5000',\n",
    "    '--served-model-name', 'test-model',\n",
    "    '--enable-reasoning', \n",
    "    '--reasoning-parser', 'qwen3',\n",
    "    '--tensor-parallel-size', os.environ['VLLM_TENSOR_PARALLEL_SIZE'],\n",
    "    '--download-dir', os.environ['HF_HOME']\n",
    "], env={**os.environ, 'CUDA_VISIBLE_DEVICES': os.environ['POLICY_MODEL_GPUS']},\n",
    "   stdout=open(f\"{LOG_DIR}/vllm-server-model.log\", 'w'),\n",
    "   stderr=subprocess.STDOUT)\n",
    "\n",
    "!sleep 120"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0087a27",
   "metadata": {},
   "source": [
    "## Content Safety - Aegis v2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55099a66",
   "metadata": {},
   "source": [
    "Launch a vLLM server for the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bb704e8c-e0bf-49a0-b2ea-07c43b44bc4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args=['pkill', '-f', 'vllm.entrypoints.openai.api_server'], returncode=0)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subprocess.run(['pkill', '-f', 'vllm.entrypoints.openai.api_server'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49850be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "# Download the file\n",
    "huggingface-cli download nvidia/Aegis-AI-Content-Safety-Dataset-2.0 test.json --repo-type dataset\n",
    "mv test.json ${AEGIS_V2_TEST_DIR}/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20b769c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AegisV2Evaluator:\n",
    "    def __init__(self, model_name,\n",
    "                 port: int = 5000,\n",
    "                 ):\n",
    "        self.client = openai.OpenAI(\n",
    "            base_url=f\"http://localhost:{port}/v1\",\n",
    "            api_key=\"EMPTY\"\n",
    "        )\n",
    "        self.model_name = model_name\n",
    "        self.port = port\n",
    "        self.output_key = output_key\n",
    "\n",
    "    def query_server(self, client, messages, model_name, temperature, top_p, max_tokens, number_of_generations=1):\n",
    "        response = client.chat.completions.create(\n",
    "            model=model_name,\n",
    "            messages=messages,\n",
    "            max_tokens=max_tokens,\n",
    "            temperature=temperature,\n",
    "            top_p=top_p,\n",
    "            stream=False,\n",
    "            n=number_of_generations\n",
    "        )\n",
    "        if number_of_generations == 1:\n",
    "            return response.choices[0].message.content\n",
    "        else:\n",
    "            return [choice.message.content for choice in response.choices]\n",
    "\n",
    "    def query_single(self, data, idx, temperature=0.6, top_p=0.95, tokens_to_generate=8192, number_of_generations=1):\n",
    "        \"\"\"Function to wrap openai client code for a single data item\"\"\"\n",
    "        messages = [{\"role\": \"user\", \"content\": data['prompt']}]\n",
    "        try:\n",
    "            result = self.query_server(self.client, messages, self.model_name,\n",
    "                                       temperature,\n",
    "                                       top_p,\n",
    "                                       tokens_to_generate,\n",
    "                                       number_of_generations)\n",
    "            return result, idx\n",
    "        except Exception as e:\n",
    "            return f\"Error: {e}\"\n",
    "\n",
    "    def query_batch(self,\n",
    "                    data_list,\n",
    "                    num_workers: int = 256,\n",
    "                    temperature: float = 0.6,\n",
    "                    top_p: float = 0.95,\n",
    "                    tokens_to_generate: int = 8192,\n",
    "                    number_of_generations: int = 1):\n",
    "        \"\"\"Add progress bar for query_batch\"\"\"\n",
    "        results = [None for _ in range(len(data_list))]\n",
    "        with concurrent.futures.ThreadPoolExecutor(max_workers=num_workers) as executor:\n",
    "            futures = [executor.submit(self.query_single, data, idx, temperature, top_p, tokens_to_generate, number_of_generations) for idx, data in enumerate(data_list)]\n",
    "            for future in tqdm(concurrent.futures.as_completed(futures), total=len(futures), desc=\"Querying\"):\n",
    "                pred, idx = future.result()\n",
    "                results[idx] = pred\n",
    "        return results\n",
    "    \n",
    "    def run_evaluation(self,\n",
    "                       num_workers: int = 256,\n",
    "                       temperature: float = 0.6,\n",
    "                       top_p: float = 0.95,\n",
    "                       tokens_to_generate: int = 8192,\n",
    "                       number_of_generations: int = 1,\n",
    "                       test_filepath: str = None,\n",
    "                       pred_filepath: str = None,\n",
    "                       output_key: str = \"generated_response\"):\n",
    "        \"\"\"Run evaluation for Aegis v2\"\"\"\n",
    "        test_examples = [json.loads(line) for line in open(test_filepath)]\n",
    "        predictions = self.query_batch(test_examples,\n",
    "                                       num_workers=num_workers,\n",
    "                                       temperature=temperature,\n",
    "                                       top_p=top_p,\n",
    "                                       tokens_to_generate=tokens_to_generate,\n",
    "                                       number_of_generations=number_of_generations)\n",
    "        results = []\n",
    "        for test, pred in zip(test_examples, predictions):\n",
    "            if isinstance(pred, list):\n",
    "                for p in pred:\n",
    "                    results.append({output_key: p, **test})\n",
    "            else:\n",
    "                test[output_key] = pred\n",
    "                results.append(test)\n",
    "\n",
    "        with open(pred_filepath, 'w') as f:\n",
    "            for d in results:\n",
    "                f.write(json.dumps(d) + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c03a34a",
   "metadata": {},
   "source": [
    "```\n",
    "# * Aegis v2\n",
    "$ safety-eval  --model-name  \"deepseek-ai/deepseek-r1-distill-llama-8b\" \\\n",
    "               --model-url http://localhost:8000/v1 \\\n",
    "               --judge-url  https://b319a99a-5241-4459-b641-7219ad0fd86d.invocation.api.nvcf.nvidia.com/v1  \\\n",
    "               --results-dir results/aegis \\\n",
    "               --concurrency 64  \\\n",
    "               --eval aegis_v2 \\\n",
    "               --inference_params temperature=0.6,top_p=0.95,max_completion_tokens=12000 --limit 1\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37b66676",
   "metadata": {},
   "outputs": [],
   "source": [
    "aegis_v2_evaluator = AegisV2Evaluator(model_name=\"test-model\", port=5000)\n",
    "aegis_v2_evaluator.run_evaluation(test_filepath=f\"{DATASET_DIR}/aegis_v2/test.jsonl\",\n",
    "                                  pred_filepath=f\"{AEGIS_V2_RESULTS_DIR}/pred.jsonl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9d25355a-600e-4ee4-ac1d-328a5ee3c0a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mDEPRECATION: Loading egg at /usr/local/lib/python3.12/dist-packages/opt_einsum-3.4.0-py3.12.egg is deprecated. pip 25.1 will enforce this behaviour change. A possible replacement is to use pip for package installation. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mDEPRECATION: Loading egg at /usr/local/lib/python3.12/dist-packages/nvfuser-0.2.26a0+c5e1555-py3.12-linux-x86_64.egg is deprecated. pip 25.1 will enforce this behaviour change. A possible replacement is to use pip for package installation. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mDEPRECATION: Loading egg at /usr/local/lib/python3.12/dist-packages/looseversion-1.3.0-py3.12.egg is deprecated. pip 25.1 will enforce this behaviour change. A possible replacement is to use pip for package installation. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mDEPRECATION: Loading egg at /usr/local/lib/python3.12/dist-packages/lightning_utilities-0.14.0-py3.12.egg is deprecated. pip 25.1 will enforce this behaviour change. A possible replacement is to use pip for package installation. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mDEPRECATION: Loading egg at /usr/local/lib/python3.12/dist-packages/lightning_thunder-0.2.2.dev0-py3.12.egg is deprecated. pip 25.1 will enforce this behaviour change. A possible replacement is to use pip for package installation. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mDEPRECATION: Loading egg at /usr/local/lib/python3.12/dist-packages/deep_ep-1.0.0+a84a248-py3.12-linux-x86_64.egg is deprecated. pip 25.1 will enforce this behaviour change. A possible replacement is to use pip for package installation. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n",
      "\u001b[0mLooking in indexes: https://gitlab-master.nvidia.com/api/v4/projects/153108/packages/pypi/simple\n",
      "Collecting nvidia-safety-harness==0.0.dev0+97c4fdc3\n",
      "  Downloading https://gitlab-master.nvidia.com/api/v4/projects/153108/packages/pypi/files/1ad08677f62c5e2c2f9f8bc97ce1624bdb4a0b293aee06e9c4b69a845b7f47ea/nvidia_safety_harness-0.0.dev0%2B97c4fdc3-py3-none-any.whl (70 kB)\n",
      "Requirement already satisfied: langchain in /usr/local/lib/python3.12/dist-packages (from nvidia-safety-harness==0.0.dev0+97c4fdc3) (0.3.25)\n",
      "Requirement already satisfied: langchain_openai in /usr/local/lib/python3.12/dist-packages (from nvidia-safety-harness==0.0.dev0+97c4fdc3) (0.3.18)\n",
      "Requirement already satisfied: more_itertools in /usr/local/lib/python3.12/dist-packages/setuptools/_vendor (from nvidia-safety-harness==0.0.dev0+97c4fdc3) (10.3.0)\n",
      "Requirement already satisfied: pandas>=2.2.3 in /usr/local/lib/python3.12/dist-packages (from nvidia-safety-harness==0.0.dev0+97c4fdc3) (2.2.3)\n",
      "Requirement already satisfied: datasets>=2.19.1 in /usr/local/lib/python3.12/dist-packages (from nvidia-safety-harness==0.0.dev0+97c4fdc3) (3.6.0)\n",
      "Requirement already satisfied: rich>=14.0.0 in /usr/local/lib/python3.12/dist-packages (from nvidia-safety-harness==0.0.dev0+97c4fdc3) (14.0.0)\n",
      "Requirement already satisfied: omegaconf>=2.3.0 in /usr/local/lib/python3.12/dist-packages (from nvidia-safety-harness==0.0.dev0+97c4fdc3) (2.3.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from datasets>=2.19.1->nvidia-safety-harness==0.0.dev0+97c4fdc3) (3.17.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from datasets>=2.19.1->nvidia-safety-harness==0.0.dev0+97c4fdc3) (1.26.4)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets>=2.19.1->nvidia-safety-harness==0.0.dev0+97c4fdc3) (15.0.2)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets>=2.19.1->nvidia-safety-harness==0.0.dev0+97c4fdc3) (0.3.8)\n",
      "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.12/dist-packages (from datasets>=2.19.1->nvidia-safety-harness==0.0.dev0+97c4fdc3) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.12/dist-packages (from datasets>=2.19.1->nvidia-safety-harness==0.0.dev0+97c4fdc3) (4.67.1)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets>=2.19.1->nvidia-safety-harness==0.0.dev0+97c4fdc3) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.12/dist-packages (from datasets>=2.19.1->nvidia-safety-harness==0.0.dev0+97c4fdc3) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.19.1->nvidia-safety-harness==0.0.dev0+97c4fdc3) (2024.3.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.12/dist-packages (from datasets>=2.19.1->nvidia-safety-harness==0.0.dev0+97c4fdc3) (0.32.3)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from datasets>=2.19.1->nvidia-safety-harness==0.0.dev0+97c4fdc3) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from datasets>=2.19.1->nvidia-safety-harness==0.0.dev0+97c4fdc3) (6.0.2)\n",
      "Requirement already satisfied: antlr4-python3-runtime==4.9.* in /usr/local/lib/python3.12/dist-packages (from omegaconf>=2.3.0->nvidia-safety-harness==0.0.dev0+97c4fdc3) (4.9.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas>=2.2.3->nvidia-safety-harness==0.0.dev0+97c4fdc3) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=2.2.3->nvidia-safety-harness==0.0.dev0+97c4fdc3) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=2.2.3->nvidia-safety-harness==0.0.dev0+97c4fdc3) (2025.1)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=14.0.0->nvidia-safety-harness==0.0.dev0+97c4fdc3) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=14.0.0->nvidia-safety-harness==0.0.dev0+97c4fdc3) (2.19.1)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.58 in /usr/local/lib/python3.12/dist-packages (from langchain->nvidia-safety-harness==0.0.dev0+97c4fdc3) (0.3.62)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in /usr/local/lib/python3.12/dist-packages (from langchain->nvidia-safety-harness==0.0.dev0+97c4fdc3) (0.3.8)\n",
      "Requirement already satisfied: langsmith<0.4,>=0.1.17 in /usr/local/lib/python3.12/dist-packages (from langchain->nvidia-safety-harness==0.0.dev0+97c4fdc3) (0.3.43)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langchain->nvidia-safety-harness==0.0.dev0+97c4fdc3) (2.11.4)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.12/dist-packages (from langchain->nvidia-safety-harness==0.0.dev0+97c4fdc3) (2.0.40)\n",
      "Requirement already satisfied: openai<2.0.0,>=1.68.2 in /usr/local/lib/python3.12/dist-packages (from langchain_openai->nvidia-safety-harness==0.0.dev0+97c4fdc3) (1.82.1)\n",
      "Requirement already satisfied: tiktoken<1,>=0.7 in /usr/local/lib/python3.12/dist-packages (from langchain_openai->nvidia-safety-harness==0.0.dev0+97c4fdc3) (0.7.0)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.19.1->nvidia-safety-harness==0.0.dev0+97c4fdc3) (3.11.13)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.24.0->datasets>=2.19.1->nvidia-safety-harness==0.0.dev0+97c4fdc3) (4.12.2)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.24.0->datasets>=2.19.1->nvidia-safety-harness==0.0.dev0+97c4fdc3) (1.1.2)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.58->langchain->nvidia-safety-harness==0.0.dev0+97c4fdc3) (9.0.0)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.58->langchain->nvidia-safety-harness==0.0.dev0+97c4fdc3) (1.33)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<0.4,>=0.1.17->langchain->nvidia-safety-harness==0.0.dev0+97c4fdc3) (0.27.0)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.12/dist-packages (from langsmith<0.4,>=0.1.17->langchain->nvidia-safety-harness==0.0.dev0+97c4fdc3) (3.10.18)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<0.4,>=0.1.17->langchain->nvidia-safety-harness==0.0.dev0+97c4fdc3) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<0.4,>=0.1.17->langchain->nvidia-safety-harness==0.0.dev0+97c4fdc3) (0.23.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=14.0.0->nvidia-safety-harness==0.0.dev0+97c4fdc3) (0.1.2)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from openai<2.0.0,>=1.68.2->langchain_openai->nvidia-safety-harness==0.0.dev0+97c4fdc3) (4.8.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai<2.0.0,>=1.68.2->langchain_openai->nvidia-safety-harness==0.0.dev0+97c4fdc3) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from openai<2.0.0,>=1.68.2->langchain_openai->nvidia-safety-harness==0.0.dev0+97c4fdc3) (0.9.0)\n",
      "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai<2.0.0,>=1.68.2->langchain_openai->nvidia-safety-harness==0.0.dev0+97c4fdc3) (1.3.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain->nvidia-safety-harness==0.0.dev0+97c4fdc3) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain->nvidia-safety-harness==0.0.dev0+97c4fdc3) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain->nvidia-safety-harness==0.0.dev0+97c4fdc3) (0.4.0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas>=2.2.3->nvidia-safety-harness==0.0.dev0+97c4fdc3) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets>=2.19.1->nvidia-safety-harness==0.0.dev0+97c4fdc3) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets>=2.19.1->nvidia-safety-harness==0.0.dev0+97c4fdc3) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets>=2.19.1->nvidia-safety-harness==0.0.dev0+97c4fdc3) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets>=2.19.1->nvidia-safety-harness==0.0.dev0+97c4fdc3) (2025.1.31)\n",
      "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from SQLAlchemy<3,>=1.4->langchain->nvidia-safety-harness==0.0.dev0+97c4fdc3) (3.2.1)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.12/dist-packages (from tiktoken<1,>=0.7->langchain_openai->nvidia-safety-harness==0.0.dev0+97c4fdc3) (2024.11.6)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.19.1->nvidia-safety-harness==0.0.dev0+97c4fdc3) (2.5.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.19.1->nvidia-safety-harness==0.0.dev0+97c4fdc3) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.19.1->nvidia-safety-harness==0.0.dev0+97c4fdc3) (25.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.19.1->nvidia-safety-harness==0.0.dev0+97c4fdc3) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.19.1->nvidia-safety-harness==0.0.dev0+97c4fdc3) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.19.1->nvidia-safety-harness==0.0.dev0+97c4fdc3) (0.3.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.19.1->nvidia-safety-harness==0.0.dev0+97c4fdc3) (1.18.3)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain->nvidia-safety-harness==0.0.dev0+97c4fdc3) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain->nvidia-safety-harness==0.0.dev0+97c4fdc3) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.58->langchain->nvidia-safety-harness==0.0.dev0+97c4fdc3) (3.0.0)\n",
      "Installing collected packages: nvidia-safety-harness\n",
      "  Attempting uninstall: nvidia-safety-harness\n",
      "    Found existing installation: nvidia-safety-harness 25.5rc1\n",
      "    Uninstalling nvidia-safety-harness-25.5rc1:\n",
      "      Successfully uninstalled nvidia-safety-harness-25.5rc1\n",
      "Successfully installed nvidia-safety-harness-0.0.dev0+97c4fdc3\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install nvidia-safety-harness==0.0.dev0+97c4fdc3  --index-url https://gitlab-master.nvidia.com/api/v4/projects/153108/packages/pypi/simple"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4841650-8d8c-42e3-8d8d-fad58cae5edf",
   "metadata": {},
   "source": [
    "### Use `safety-eval` to run Aegis v2 evaluation\n",
    "\n",
    "Use `safety-eval` to run Aegis v2 evaluation. It will take ~10min if you launch the vLLM server with 8x H100 GPUs.\n",
    "\n",
    "Check the log file `$LOG_DIR/safety-eval-aegis-v2.log` for progress."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9f0c85b6-932f-4bcd-b156-c74e880b50f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "!safety-eval --model-name \"test-model\" \\\n",
    "             --model-url http://localhost:5000/v1 \\\n",
    "             --judge-url https://b319a99a-5241-4459-b641-7219ad0fd86d.invocation.api.nvcf.nvidia.com/v1   \\\n",
    "             --results-dir {AEGIS_V2_RESULTS_DIR} \\\n",
    "             --concurrency 64 \\\n",
    "             --eval aegis_v2 \\\n",
    "             --inference_params \"temperature=0.6,top_p=0.95,max_completion_tokens=6000\" &> \"$LOG_DIR/safety-eval-aegis-v2.log\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76ef86cf-10ec-4ec2-8f3b-9e739be909ce",
   "metadata": {},
   "source": [
    "### Content Safety - WildGuard\n",
    "\n",
    "For WildGuard evaluation, a gated dataset `allenai/wildguardmix` hosted on the HF Dataset Hub will be used. Visit the dataset page at https://huggingface.co/datasets/allenai/wildguardmix to ask for access.\n",
    "\n",
    "Make sure to use the HF token associated with the account with the access.\n",
    "\n",
    "Use `safety-eval` to run WildGuard evaluation. It will take ~Xmin if you launch the vLLM server with 8x H100 GPUs.\n",
    "\n",
    "Check the log file `$LOG_DIR/safety-eval-wildguard.log` for progress."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e940a9df-9918-49b1-9800-4086b7812bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "!safety-eval --model-name \"test-model\" \\\n",
    "             --model-url http://localhost:5000/v1 \\\n",
    "             --judge-url https://d27e7649-daf1-46c2-ba22-49374402c31d.invocation.api.nvcf.nvidia.com/v1 \\\n",
    "             --results-dir {WILDGUARD_RESULTS_DIR} \\\n",
    "             --concurrency 64 \\\n",
    "             --eval wildguard \\\n",
    "             --inference_params \"temperature=0.6,top_p=0.95,max_completion_tokens=12000\" &> \"$LOG_DIR/safety-eval-wildguard.log\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dca2b8c",
   "metadata": {},
   "source": [
    "## Product Security - Garak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f656d4e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bf228950",
   "metadata": {},
   "source": [
    "## Accuracy - GPQA-D, MATH-500, AIME2024, IFEval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3386e1bb-2b98-4e76-9fc2-7edc0de78863",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args=['simple_evals', '--model', 'test-model', '--url', 'http://localhost:5000/v1/chat/completions', '--eval_name', 'gpqa_diamond', '--temperature', '0.6', '--top_p', '0.95', '--max_tokens', '8192', '--out_dir', 'results/baseline-evals/gpqa-diamond', '--cache_dir', 'results/baseline-evals/gpqa-diamond', '--num_threads', '4', '--max_retries', '5', '--timeout', '150'], returncode=0)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subprocess.run(\n",
    "    [\n",
    "        \"simple_evals\",\n",
    "        \"--model\", 'test-model',\n",
    "        \"--url\", \"http://localhost:5000/v1/chat/completions\",\n",
    "        \"--eval_name\", \"gpqa_diamond\",\n",
    "        \"--temperature\", \"0.6\",\n",
    "        \"--top_p\", \"0.95\",\n",
    "        \"--max_tokens\", \"8192\",\n",
    "        \"--out_dir\", f\"results/baseline-evals/gpqa-diamond\",\n",
    "        \"--cache_dir\", f\"results/baseline-evals/gpqa-diamond\",\n",
    "        \"--num_threads\", \"4\",\n",
    "        \"--max_retries\", \"5\",\n",
    "        \"--timeout\", \"150\"\n",
    "    ],\n",
    "    stdout=open(f\"{os.getenv('LOG_DIR')}/baseline-eval-gpqa-diamond.log\", \"w\"),\n",
    "    stderr=subprocess.STDOUT,\n",
    "    start_new_session=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a5671d79-dd04-4531-b377-5e5375edbebd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args=['simple_evals', '--model', 'test-model', '--url', 'http://localhost:5000/v1/chat/completions', '--eval_name', 'AA_math_test_500', '--temperature', '0.6', '--top_p', '0.95', '--max_tokens', '8192', '--out_dir', 'results/baseline-evals/aa-math-500', '--cache_dir', 'results/baseline-evals/aa-math-500', '--num_threads', '4', '--max_retries', '5', '--timeout', '150'], returncode=1)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subprocess.run(\n",
    "    [\n",
    "        \"simple_evals\",\n",
    "        \"--model\", 'test-model',\n",
    "        \"--url\", \"http://localhost:5000/v1/chat/completions\",\n",
    "        \"--eval_name\", \"AA_math_test_500\",\n",
    "        \"--temperature\", \"0.6\",\n",
    "        \"--top_p\", \"0.95\",\n",
    "        \"--max_tokens\", \"8192\",\n",
    "        \"--out_dir\", f\"results/baseline-evals/aa-math-500\",\n",
    "        \"--cache_dir\", f\"results/baseline-evals/aa-math-500\",\n",
    "        \"--num_threads\", \"4\",\n",
    "        \"--max_retries\", \"5\",\n",
    "        \"--timeout\", \"150\"\n",
    "    ],\n",
    "    stdout=open(f\"{os.getenv('LOG_DIR')}/baseline-eval-aa-math-500.log\", \"w\"),\n",
    "    stderr=subprocess.STDOUT,\n",
    "    start_new_session=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ec153c85-d822-480e-82e3-9c12344d87aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "process = subprocess.Popen(\n",
    "    [\n",
    "        \"lm-eval\",\n",
    "        \"--tasks\", \"ifeval\",\n",
    "        \"--num_fewshot\", \"0\",\n",
    "        \"--model\", \"local-chat-completions\",\n",
    "        \"--model_args\", \"base_url=http://localhost:5000/v1/chat/completions,model=test-model,tokenized_requests=false,num_concurrent=4,max_gen_toks=8192,timeout=150,max_retries=5,stream=False\",\n",
    "        \"--log_samples\",\n",
    "        \"--output_path\", f\"results/baseline-evals/ifeval\",\n",
    "        \"--use_cache\", f\"results/baseline-evals/ifeval\",\n",
    "        \"--fewshot_as_multiturn\",\n",
    "        \"--apply_chat_template\",\n",
    "        \"--gen_kwargs\", \"temperature=0.6,top_p=0.95\"\n",
    "    ],\n",
    "    stdout=open(f\"{os.getenv('LOG_DIR')}/baseline-eval-ifeval.log\", \"w\"),\n",
    "    stderr=subprocess.STDOUT,\n",
    "    start_new_session=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cb7c8d7-749c-4a6b-860c-118527e6773c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
